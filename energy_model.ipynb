{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from pgm.layers import MarkovChainLayer, OneHotLayer, Layer\n",
    "from pgm.data import Seq_SS_Data\n",
    "from pgm.ebm import EnergyModel\n",
    "from pgm.nn import ConvNet, ConvBlock\n",
    "from pgm.metrics import hinge_loss, aa_acc\n",
    "from pgm.utils import I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"/home/cyril/Documents/These/data/secondary_structure\"\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Seq_SS_Data(f\"{DATA}/secondary_structure_train.json\", size = 512)\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, \n",
    "                          shuffle = True, drop_last=True)\n",
    "\n",
    "val_dataset = Seq_SS_Data(f\"{DATA}/secondary_structure_valid.json\", size = 512)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, \n",
    "                        shuffle = True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.zeros((3, 3))\n",
    "for seq, length in zip(train_dataset.ss3, train_dataset.length):\n",
    "    seq = np.argmax(seq, -1)\n",
    "    x = seq[0]\n",
    "    y = seq[0]\n",
    "    for i in range(2, length):\n",
    "        x, y = y, seq[i]\n",
    "        t[x,y] += 1\n",
    "t /= np.sum(t, 1)\n",
    "t = torch.tensor(t).float()\n",
    "t = (t+t.t())/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.normal import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(): \n",
    "    return nn.LeakyReLU(0.2, inplace = False)\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size = 3, bias=True):\n",
    "        super(ResBlock, self).__init__()\n",
    "        pad = (kernel_size-1)//2\n",
    "        self.conv_1 = ConvBlock(nn.Conv1d, leaky_relu, nn.BatchNorm1d, \n",
    "                                in_channels, out_channels, kernel_size,\n",
    "                                stride=1, padding=pad, bias=bias)\n",
    "        self.conv2 = ConvBlock(nn.Conv1d, None, nn.BatchNorm1d, \n",
    "                                in_channels, out_channels, 1,\n",
    "                                stride=1, padding=0, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_1(x)\n",
    "        identity = self.conv2(x)\n",
    "        out += identity\n",
    "        return out\n",
    "    \n",
    "class ResBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=True):\n",
    "        super(ResBlock2, self).__init__()\n",
    "        self.conv_11 = ConvBlock(nn.Conv1d, leaky_relu, nn.BatchNorm1d, \n",
    "                                in_channels, out_channels, 3,\n",
    "                                stride=1, padding=1, bias=bias)\n",
    "        self.conv_12 = ConvBlock(nn.Conv1d, leaky_relu, nn.BatchNorm1d, \n",
    "                                out_channels, out_channels, 3,\n",
    "                                stride=2, padding=1, bias=bias)\n",
    "        self.conv2 = ConvBlock(nn.Conv1d, None, None, \n",
    "                                in_channels, out_channels, 3,\n",
    "                                stride=2, padding=1, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.conv_11(x)\n",
    "        out = self.conv_12(out)\n",
    "        identity = self.conv2(x)\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels = 100, bias=True):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.in_channels, self.out_channels = in_channels, out_channels\n",
    "        self.conv1 = ResBlock(in_channels, 100, 11)\n",
    "        self.conv2 = ResBlock(100, 100, 11)\n",
    "        self.conv3 = ResBlock(100, 100, 11)\n",
    "        self.conv4 = ResBlock(100, 100, 11)\n",
    "#         self.conv5 = ResBlock(100, 100, 11)\n",
    "        self.conv5 = ConvBlock(nn.Conv1d, nn.PReLU, nn.BatchNorm1d,\n",
    "                        100, out_channels, 1,\n",
    "                        stride=1, padding=0, dilation=1)\n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.conv2(h)\n",
    "#         h = self.conv3(h)\n",
    "#         h = self.conv4(h)\n",
    "        h = self.conv5(h)\n",
    "        return h\n",
    "    \n",
    "class ConvNet2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels = 100, bias=True):\n",
    "        super(ConvNet2, self).__init__()\n",
    "        self.in_channels, self.out_channels = in_channels, out_channels\n",
    "        \n",
    "#         self.att1 = SelfAttention(in_channels)\n",
    "        self.l_conv1 = ResBlock(in_channels, 100, 5)\n",
    "        self.l_conv2 = ResBlock(100, out_channels, 5)\n",
    "        self.l_pool1 = nn.MaxPool1d(2) # 256\n",
    "\n",
    "        self.m_conv1 = ResBlock2(out_channels, out_channels // 2, 5)\n",
    "        self.m_pool1 = nn.MaxPool1d(2) # 64\n",
    "        \n",
    "        self.g_conv1 = ResBlock2(out_channels, out_channels, 5)\n",
    "        self.g_pool1 = nn.MaxPool1d(2) # 64\n",
    "        self.g_conv2 = ResBlock2(out_channels, out_channels // 2, 5)\n",
    "        self.g_pool2 = nn.MaxPool1d(2) # 16\n",
    "        self.g_conv3 = ResBlock2(out_channels // 2, out_channels // 2, 5)\n",
    "        self.g_pool3 = nn.MaxPool1d(2) # 4\n",
    "\n",
    "\n",
    "        self.g_dense = nn.Linear(out_channels * 2, out_channels//2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, N = x.size()\n",
    "        h_l = self.l_conv1(x)\n",
    "        h_l = self.l_conv2(h_l)\n",
    "        h = self.l_pool1(h_l)\n",
    "        \n",
    "        h_m = self.m_pool1(self.m_conv1(h))\n",
    "        h_m = torch.cat([h_m[:,:,i:i+1].expand(-1, -1, N//h_m.size(-1)) for i in range(h_m.size(-1))], -1)\n",
    "\n",
    "        h_g = self.g_pool1(self.g_conv1(h))\n",
    "        h_g = self.g_pool2(self.g_conv2(h_g))\n",
    "        h_g = self.g_pool3(self.g_conv3(h_g)).view(batch_size, -1)\n",
    "        h_g = self.g_dense(h_g).view(batch_size, -1, 1)\n",
    "        h_g = h_g.expand(-1, -1, N)\n",
    "\n",
    "        return torch.cat([h_l, h_m, h_g], 1)\n",
    "    \n",
    "class ConvNet3(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels = 100, N = 128, bias=True):\n",
    "        super(ConvNet3, self).__init__()\n",
    "        self.in_channels, self.out_channels = in_channels, out_channels\n",
    "        self.conv1 = ResBlock(in_channels, 100, 11)\n",
    "        self.conv2 = ResBlock(100, 100, 11)\n",
    "        self.lstm = nn.LSTM(input_size = 100, \n",
    "                            hidden_size = out_channels, \n",
    "                            num_layers = 2,\n",
    "                            bias = True,\n",
    "                            bidirectional = True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.conv2(h)\n",
    "        h = h.permute(2, 0, 1)\n",
    "        h = self.lstm(h)[0]\n",
    "        return h.permute(1, 2, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMMLayer(Layer):\n",
    "    r\"\"\"\n",
    "    Layer of One Hot neurons linked by a Markov Chain\n",
    "\n",
    "    Args:\n",
    "        T (Numpy Array): Transition Matrix for the Markov Chain\n",
    "        N (Integer): Number of neurons\n",
    "        q (Integer): Number of values the neuron can take\n",
    "        name (String): Name of the layer\n",
    "    \"\"\"\n",
    "    def __init__(self, T, N = 100, q = 21, h = 100, name = \"layer0\"):\n",
    "        super(HMMLayer, self).__init__(name)\n",
    "        self.full_name = f\"MC_{name}\"\n",
    "        self.N = N\n",
    "        self.q = q\n",
    "        self.h = h\n",
    "        self.T = nn.Parameter(T.float(), requires_grad=True)\n",
    "        self.mu = nn.Parameter(torch.rand(self.q, self.h)/self.h, requires_grad=True)\n",
    "        self.sig = nn.Parameter(torch.rand(self.q, self.h, self.h)/self.h, requires_grad=True)\n",
    "        \n",
    "    def E(self, x, l):\n",
    "        tau = taus(x, self.T, self.mu, self.sig, l)\n",
    "        return tau\n",
    "    \n",
    "    def max_likelihood(self, x):\n",
    "        return calcul_tau(x, self.T, self.mu, max_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnergyModel(nn.Module):\n",
    "    def __init__(self, xlay, ylay, Dx = I, Dy = I):\n",
    "        super(EnergyModel, self).__init__()\n",
    "        self.Dx, self.Dy = Dx, Dy\n",
    "        self.xlay, self.ylay = xlay, ylay\n",
    "                \n",
    "    def energy(self, x):\n",
    "        x = x.detach()\n",
    "        Dx = self.Dx(x)\n",
    "        e = self.ylay.E(Dx)\n",
    "        return e\n",
    "    \n",
    "    def forward(self, x, l):\n",
    "        x = x.detach()\n",
    "        Dx = self.Dx(x)\n",
    "        e = self.ylay.E(Dx, l)\n",
    "        return e\n",
    "    \n",
    "    def ypredict(self, x):\n",
    "        x = x.detach()\n",
    "        Dx = self.Dx(x)\n",
    "        e = self.ylay.max_likelihood(Dx)\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def log_pdf(x, mu, sigma = None):\n",
    "    N = mu.size(0)\n",
    "    y = x - mu\n",
    "    Sy = y\n",
    "    sigma = (1/N) * torch.eye(N)\n",
    "    if sigma is not None:\n",
    "        Sy = sigma.mv(x)\n",
    "    logZ = (N/2)*math.log(2 * math.pi/N)\n",
    "    return -0.5*(y * Sy).sum() - logZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_op = lambda x : torch.sum(x, 0)\n",
    "max_op = lambda x : torch.max(x, dim = 0)[0]\n",
    "\n",
    "def alphas(Dx, T, mu, sigma, operator = sum_op):\n",
    "    _, N = Dx.size()\n",
    "    k = mu.size(0)\n",
    "    log_alphas = torch.zeros(k, N)\n",
    "    log_norm = torch.zeros(N)\n",
    "    \n",
    "    log_alphas[:,0] = torch.cat([log_pdf(Dx[:,0], mu[j]).view(-1,1) for j in range(k)],1)\n",
    "    log_norm[0] = torch.log((torch.exp(log_alphas[:,0])).sum())\n",
    "    for s in range(1,N):\n",
    "        for j in range(k):\n",
    "            log_alphas[j,s] = log_norm[s-1] + log_pdf(Dx[:,s], mu[j]) \n",
    "            log_alphas[j,s] += torch.logsumexp(log_alphas[:,s-1] - log_norm[s-1] + torch.log(T[:,j]), 0)\n",
    "        log_norm[s] = log_norm[s-1] + torch.log(torch.exp(log_alphas[:,s]-log_norm[s-1]).sum()) \n",
    "    return(log_alphas, log_norm)\n",
    "\n",
    "def betas(Dx, T, mu, sigma, operator = sum_op):\n",
    "    q, N = Dx.size()\n",
    "    k = mu.size(0)\n",
    "    log_betas = torch.zeros(k, N)\n",
    "    log_norm = torch.zeros(N)\n",
    "    \n",
    "    log_norm[-1] = torch.log(torch.exp(log_betas[:, -1]).sum())\n",
    "    for s in range(2,N+1):\n",
    "        for j in range(k):\n",
    "            log_betas[j,-s] = log_norm[-s+1] + torch.logsumexp(\n",
    "                    torch.tensor([log_pdf(Dx[:,-s+1], mu[i]) + log_betas[i,-s+1] - log_norm[-s+1] + torch.log(T[j,i]) for i in range(k)]), 0)\n",
    "        log_norm[-s] = log_norm[-s+1] + torch.log(torch.exp(log_betas[:,-s] - log_norm[-s+1]).sum())\n",
    "\n",
    "    return(log_betas, log_norm)\n",
    "\n",
    "def taus(Dx, T, mu, sigma, lengths, operator = sum_op):\n",
    "    batch_size, _, N = Dx.size()\n",
    "    tau = torch.zeros(batch_size, mu.size(0), N)\n",
    "    for i, l in enumerate(lengths):\n",
    "        log_alp, lnorma = alphas(Dx[i,:,:l], T, mu, sigma, operator)\n",
    "        log_bet, lnormb = betas(Dx[i,:,:l], T, mu, sigma, operator)\n",
    "        tau[i,:, :l] = log_alp - lnorma.view(1, -1) + log_bet - lnormb.view(1, -1) \n",
    "#     tau /= tau.sum(-1).view(batch_size, tau.size(1), 1)\n",
    "\n",
    "#     for s in range(N):\n",
    "#         alp_norm[:,:, s] = torch.exp(log_alp[:,:,s] - lnorma[:, s].view(-1, 1))\n",
    "#         beta_norm[:,:, s] = torch.exp(log_bet[:,:,s] - lnormb[:, s].view(-1, 1))\n",
    "#     tau2 = torch.zeros((batch_size, k, k, N-1))\n",
    "    \n",
    "#     for q1 in range(k):\n",
    "#         for q2 in range(k):\n",
    "#             tau2[:,q1,q2,:] = alp_norm[:,q1,:]*bet_norm[:,q2,:]\n",
    "#     for s2 in range(k):\n",
    "#         for s in range(N-1):\n",
    "#             tau2[:,:,:,:]*=log_pdf(Dx[:,:,s+1], mu[s2], sigma[s2])\n",
    "#     tau2 /= tau2.sum(-1).view(batch_size, k, k, 1)\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnergyModel(\n",
       "  (Dx): ConvNet(\n",
       "    (conv1): ResBlock(\n",
       "      (conv_1): ConvBlock(\n",
       "        (conv): Conv1d(21, 100, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "        (normalization): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv1d(21, 100, kernel_size=(1,), stride=(1,))\n",
       "        (normalization): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2): ResBlock(\n",
       "      (conv_1): ConvBlock(\n",
       "        (conv): Conv1d(100, 100, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "        (normalization): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv1d(100, 100, kernel_size=(1,), stride=(1,))\n",
       "        (normalization): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3): ResBlock(\n",
       "      (conv_1): ConvBlock(\n",
       "        (conv): Conv1d(100, 100, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "        (normalization): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv1d(100, 100, kernel_size=(1,), stride=(1,))\n",
       "        (normalization): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv4): ResBlock(\n",
       "      (conv_1): ConvBlock(\n",
       "        (conv): Conv1d(100, 100, kernel_size=(11,), stride=(1,), padding=(5,))\n",
       "        (activation): LeakyReLU(negative_slope=0.2)\n",
       "        (normalization): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv2): ConvBlock(\n",
       "        (conv): Conv1d(100, 100, kernel_size=(1,), stride=(1,))\n",
       "        (normalization): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (conv5): ConvBlock(\n",
       "      (conv): Conv1d(100, 1, kernel_size=(1,), stride=(1,))\n",
       "      (activation): PReLU(num_parameters=1)\n",
       "      (normalization): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (xlay): OneHotLayer()\n",
       "  (ylay): HMMLayer()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, qx, qs, h = 512, 21, 3, 1\n",
    "# del model\n",
    "device = torch.device('cpu')\n",
    "\n",
    "\n",
    "x = OneHotLayer(torch.zeros(qx*N), N = N, q = qx, name = \"x\")\n",
    "s = HMMLayer(t, N = N, q = qs, h = h, name = \"ss\")\n",
    "\n",
    "Dx = ConvNet(qx, h)\n",
    "Ds = I\n",
    "model = EnergyModel(x, s, Dx, Ds)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def hinge_loss(model, x, y, l, m = 1):\n",
    "    e = -model(x, l)\n",
    "    e_bar = torch.min(e+y*1e9, 1, keepdim=True).values.view(e.size(0), 1,                                              e.size(-1))\n",
    "    loss = F.relu(m+(e-e_bar)*y)\n",
    "    return loss.sum()/(l.sum()), e\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    mean_loss, mean_reg, mean_acc = 0, 0, 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        x = data[0].float().permute(0, 2, 1).to(device)\n",
    "        s = data[1].float().permute(0, 2, 1).to(device)\n",
    "        l = data[2].int().to(device)\n",
    "        length = data[2].int().to(device)\n",
    "        # Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss, pred = hinge_loss(model, x, s, l)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = aa_acc(s, pred)\n",
    "\n",
    "        del x; del s\n",
    "        # Metrics\n",
    "        mean_loss = (mean_loss*batch_idx + loss.item())/ (batch_idx+1)\n",
    "        mean_acc = acc\n",
    "        m, s = int(time.time()-start)//60, int(time.time()-start)%60\n",
    "        print(f'''Train Epoch: {epoch} [{int(100*batch_idx/len(train_loader))}%] || Time: {m} min {s} || Loss: {mean_loss:.3f} || Acc: {mean_acc:.3f}''', end=\"\\r\")\n",
    "        \n",
    "    \n",
    "def val(epoch):\n",
    "    mean_loss, mean_reg, mean_acc = 0, 0, 0\n",
    "    cm = np.zeros((3,3))\n",
    "    for batch_idx, data in enumerate(val_loader):\n",
    "        x = data[0].float().permute(0, 2, 1).to(device)\n",
    "        s = data[1].float().permute(0, 2, 1).to(device)\n",
    "        l = data[2].int().to(device)\n",
    "\n",
    "        \n",
    "        # Optimization\n",
    "        loss, pred = hinge_loss(model, x, s, l)\n",
    "        acc = aa_acc(s, pred)\n",
    "        \n",
    "        cm += confusion_matrix(s.argmax(1).view(-1), \n",
    "                         model(x).argmax(1).view(-1))\n",
    "        # Metrics\n",
    "        mean_loss = (mean_loss*batch_idx + loss.item())/ (batch_idx+1)\n",
    "        mean_acc = (mean_acc*batch_idx + acc)/ (batch_idx+1)\n",
    "        \n",
    "\n",
    "        m, s = int(time.time()-start)//60, int(time.time()-start)%60\n",
    "        print(f'''Val: {epoch} [{int(100*batch_idx/len(val_loader))}%] || Time: {m} min {s} || Loss: {mean_loss:.3f} ''', end=\"\\r\")\n",
    "    \n",
    "    print(f'''Val: {epoch} [100%] || Time: {m} min {s} || Loss: {mean_loss:.3f} || Acc: {mean_acc:.3f}           ''')\n",
    "    cm = (np.array(cm.T, dtype=np.float)/np.sum(cm, 1)).T\n",
    "    print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0%] || Time: 0 min 51 || Loss: nan || Acc: 0.39171\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-f4b80ff55f7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9f0859951988>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhinge_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9f0859951988>\u001b[0m in \u001b[0;36mhinge_loss\u001b[0;34m(model, x, y, l, m)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhinge_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0me_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m                                              \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-eace8181fbb1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, l)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mDx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-49c218926bda>\u001b[0m in \u001b[0;36mE\u001b[0;34m(self, x, l)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtaus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m#         mu = torch.cat([((tau[:,s:s+1,:] * Dx).sum(-1)/tau.sum(-1)).mean(0).view(1, -1) for s in range(self.q)],0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#         sig = torch.cat([((tau[:,s:s+1,:] * Dx).sum(-1)/tau.sum(-1)).mean(0).view(1, -1) for s in range(self.q)],0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d8a6aa4d3789>\u001b[0m in \u001b[0;36mtaus\u001b[0;34m(Dx, T, mu, sigma, lengths, operator)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mlog_alp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnorma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mlog_bet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlnormb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mtau\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_alp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlnorma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_bet\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlnormb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-d8a6aa4d3789>\u001b[0m in \u001b[0;36malphas\u001b[0;34m(Dx, T, mu, sigma, operator)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mlog_alphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mlog_alphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_alphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mlog_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_alphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlog_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-1d428f0859e4>\u001b[0m in \u001b[0;36mlog_pdf\u001b[0;34m(x, mu, sigma)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mSy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlogZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlogZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.train()\n",
    "for epoch in range(30):\n",
    "    train(epoch)\n",
    "    if not epoch%1:\n",
    "        val(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model  | Train Acc  | Val Acc |\n",
    "|---|---|---|\n",
    "| HMM  | 0.57  | 0.54  |\n",
    "| HMM + 5-Conv  | 0.971  | 0.70 |\n",
    "|   |   |   |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
