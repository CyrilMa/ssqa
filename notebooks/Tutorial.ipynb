{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSQA - Tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, random, warnings, subprocess, torch\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we recall the full pipeline for Pattern Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Data Collection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import PFAM_DATA\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dataset `DATASET` and the file `filename` where all **aligned** sequences are. The data file `data.pt` will be stored in `PFAM_DATA/DATASET` folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"PF00397\"\n",
    "filename = \"full.fasta\"\n",
    "folder = f\"{PFAM_DATA}/{DATASET}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the two first steps :\n",
    "- Clustering and splitting the clusters between training and testing set with MMSEQS\n",
    "- Build HMMer profile with HHsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building sequences.csv\n",
      "building data.pt sequences ...\n",
      "building aligned.fasta, unaligned.fasta ...\n",
      "Processing 57486 sequences ...\r"
     ]
    }
   ],
   "source": [
    "build_protein_df(f\"{folder}\", filename)\n",
    "\n",
    "# We build clusters with MMSEQS\n",
    "subprocess.run(\n",
    "    f'mmseqs easy-cluster \"{folder}/unaligned.fasta\" \"{folder}/tmp/clusters.tsv\" \"{folder}/tmp\" --min-seq-id 0.7',\n",
    "    shell=True)\n",
    "\n",
    "# We compute cluster weights\n",
    "cluster_weights(folder)\n",
    "\n",
    "# We split between training and validation set (useful for training RBM)\n",
    "split_train_val_set(folder)\n",
    "\n",
    "# We compute profiles\n",
    "subprocess.run(f'hhmake -i {folder}/aligned.fasta -M 100', shell=True)\n",
    "build_profiles(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step consists in retrieving the pattern, for this, three methods are available :\n",
    "1. Retrieving the specific structure from a known `uniprot_id`\n",
    "2. Retrieving available structure from the PFAM family `pfam_id`\n",
    "3. Use the `PatternInference` to retrieve a pattern by inference (if no pattern available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1 : Retrieving the specific structure from a known `uniprot_id`\n",
    "\n",
    "uniprot_id = \"P0A9J8\"\n",
    "nat_seq = \"TSENPLLALREKISALDEKLLALLAERRELAVEVGKAKLLSHRPVRDIDRERDLLERLITLGKAHHLDAHYITRLFQLIIEDSVLTQQALLQQH\"\n",
    "search_pattern(f\"{DATA}/{MUT_DATASET}\", uniprot_id, nat_seq)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [02:33<00:00,  1.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('cbcbcbacac',\n",
       " [2, 1, 2, 1, 2, 1, 0, 2, 0, 2],\n",
       " 'CBCTCBTCBHCHC',\n",
       " [7, 3, 7, 6, 7, 3, 6, 7, 3, 1, 7, 1, 7],\n",
       " {'cbcacbcbacac': 11,\n",
       "  'cbcbcbacac': 35,\n",
       "  'cbcbcbac': 19,\n",
       "  'cbcacbcbac': 13,\n",
       "  'cbcacbcac': 1,\n",
       "  'cbacbcacac': 1,\n",
       "  'cacacac': 2,\n",
       "  'cbcac': 2,\n",
       "  'cacbcbcbac': 4,\n",
       "  'cacbacbcbcac': 1,\n",
       "  'cbcacbcacbac': 1,\n",
       "  'cbac': 2,\n",
       "  'cbcbcacac': 1,\n",
       "  'cbcbacac': 2,\n",
       "  'cbcacbcbc': 1,\n",
       "  'cacbcbac': 3,\n",
       "  'cabcacbcbac': 4,\n",
       "  'cbcacbcbcacac': 1,\n",
       "  'cacbcacbcbac': 6,\n",
       "  'cbcbacbac': 2,\n",
       "  'cbabcbac': 1,\n",
       "  'cacbcbacbac': 1,\n",
       "  'cacacacbc': 1,\n",
       "  'cbcacbacbc': 1,\n",
       "  'cbcacbacbac': 2,\n",
       "  'cbcbac': 4,\n",
       "  'cbcbacbacac': 1,\n",
       "  'cacbcbacbcac': 1,\n",
       "  'cacbc': 2,\n",
       "  'cbacac': 1,\n",
       "  'cacbcbcbacac': 1,\n",
       "  'cabcacbacbac': 1,\n",
       "  'cabcbcbac': 2,\n",
       "  'cacbcbacacac': 1,\n",
       "  'cacbcbcbcbcac': 1,\n",
       "  'cacacbc': 1,\n",
       "  'cbcacbcbacbc': 1,\n",
       "  'cac': 1,\n",
       "  'cacbcbcacacac': 1,\n",
       "  'cabcacbacabc': 1,\n",
       "  'cbc': 1,\n",
       "  'cbcbcbcac': 1,\n",
       "  'cbcbcbc': 2,\n",
       "  'cacbcacbcacbc': 1,\n",
       "  'cbacacbcbac': 1,\n",
       "  'cacbcacbcbc': 1},\n",
       " {'CBCTHCBTCBHCHC': 7,\n",
       "  'CBCTCBTCBHCHC': 29,\n",
       "  'CBCTHCBTBHCHC': 1,\n",
       "  'CTBCTCBTCBHC': 2,\n",
       "  'CBCTCBTBHC': 1,\n",
       "  'CBCHCBTBHC': 2,\n",
       "  'CBCTHCBTCSHC': 1,\n",
       "  'CBHCBTSCHCTCHC': 1,\n",
       "  'CBTBTCBHCHC': 2,\n",
       "  'CIHCIHCHC': 1,\n",
       "  'CBCHITC': 1,\n",
       "  'CHCBTBTBHC': 3,\n",
       "  'CTBCHCBTBHC': 4,\n",
       "  'CHCBHCBTBCHC': 1,\n",
       "  'CTCBCTHCBCHCBHC': 1,\n",
       "  'CTBHC': 2,\n",
       "  'CTCBTBCHCHC': 1,\n",
       "  'CBTBHCIC': 1,\n",
       "  'CTBCTHCBTBC': 1,\n",
       "  'CSCTHCBTBHC': 1,\n",
       "  'CHBCHCBTBHC': 3,\n",
       "  'CTCBCHCBTBCHCHC': 1,\n",
       "  'CHCBCTHCBTBHC': 1,\n",
       "  'CTBTBTBHC': 2,\n",
       "  'CBTBHCBHCTC': 1,\n",
       "  'CTBCHTCBTCBHC': 1,\n",
       "  'CBHBTCBHC': 1,\n",
       "  'CTHCBTBHCEIHC': 1,\n",
       "  'CIHCIHCHCTCEC': 1,\n",
       "  'CTBCHCBHCBC': 1,\n",
       "  'CTBCTCBTBHC': 1,\n",
       "  'CTBCTHCBTBHC': 2,\n",
       "  'CITCBTBTBHC': 1,\n",
       "  'CBCTCBTCBHC': 3,\n",
       "  'CBTBTCBHC': 2,\n",
       "  'CTBCTHCBHCBHC': 1,\n",
       "  'CBTBHCTC': 1,\n",
       "  'CSCHCSBTBHCTC': 1,\n",
       "  'CBTBHCEIHCHTC': 1,\n",
       "  'CBCTHCBTCBHC': 1,\n",
       "  'CHTBCTHCBTCBHC': 3,\n",
       "  'CTBCHIHC': 1,\n",
       "  'CBTBTBHC': 5,\n",
       "  'CTHCBTBHCTETHC': 1,\n",
       "  'CTBTBTCBHC': 1,\n",
       "  'CITEC': 2,\n",
       "  'CTBCTHCBTCBHC': 2,\n",
       "  'CBHCTCIHC': 1,\n",
       "  'CTBTBHCTHC': 1,\n",
       "  'CHTBTBTBHCHC': 1,\n",
       "  'CHBCHCBHCBHC': 1,\n",
       "  'CTCBCTHCBTBHC': 1,\n",
       "  'CHBCTCBTBHC': 1,\n",
       "  'CTBTBTCBHCHC': 3,\n",
       "  'CBTBTBHCHC': 1,\n",
       "  'CHCBCHCBTBHC': 1,\n",
       "  'CTBTBHCTC': 1,\n",
       "  'CHCBTBHCTIHCHC': 1,\n",
       "  'CHCTCECBTBCBCHC': 1,\n",
       "  'CICSCITBC': 1,\n",
       "  'CBTBHC': 1,\n",
       "  'CBCHCBTBHCEC': 1,\n",
       "  'CBCHCBTCBHCHC': 1,\n",
       "  'CIC': 1,\n",
       "  'CTHCBTBCHCHCSHC': 1,\n",
       "  'CTBTBHCBHC': 1,\n",
       "  'CHBCHTCBHTHBC': 1,\n",
       "  'CBTC': 1,\n",
       "  'CTCBCTCBTBHC': 2,\n",
       "  'CBTBTBCHC': 1,\n",
       "  'CHTBCTHCBTBHC': 1,\n",
       "  'CHBCTHCBTBHC': 1,\n",
       "  'CTBTBTCBC': 1,\n",
       "  'CHCBTBHCTC': 1,\n",
       "  'CSCHCSCSTSCHCHC': 1,\n",
       "  'CTBTBHC': 1,\n",
       "  'CHBCTCBTCBHC': 1,\n",
       "  'CHCBCTHCBCHCBC': 1,\n",
       "  'CTBHTHCBTBHC': 1,\n",
       "  'CBCHTCBHCBHC': 1,\n",
       "  'CTBCHCBTCBHCHC': 1,\n",
       "  'CTBCTCBTBC': 1,\n",
       "  'CTBCTHCBTCBHCHC': 1,\n",
       "  'CHTBCHCBTBC': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 2 : Retrieving available structure from the PFAM family `pfam_id`\n",
    "\n",
    "structfam = get_structures(DATASET)\n",
    "build_patterns(structfam, f\"{PFAM_DATA}/{DATASET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3 : Use the `PatternInference` to retrieve a pattern by inference (if no pattern available)\n",
    "\n",
    "infer_pattern(f\"{PFAM_DATA}/{DATASET}\", indices = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Secondary Structure Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "The first thing to do is to train the model if it is not done (a trained model is available in `data/utils`. Here is the way to do it if you wish so with the adapted `NetSurfP2`.\n",
    "\n",
    "Reference : \n",
    "\n",
    "*NetSurfP-2.0: Improved prediction of protein structural features by integrated deep learning, Klausen, Michael Schantz and Jespersen, Martin Closter and Nielsen, Henrik and Jensen, Kamilla Kjaergaard and Jurtz, Vanessa Isabell and Soenderby, Casper Kaae and Sommer, Morten Otto Alexander and Winther, Ole and Nielsen, Morten and Petersen, Bent and others*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "from data import SecondaryStructureAnnotatedDataset, collate_sequences_train\n",
    "from ss_inference import NetSurfP2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first retrieve the dataset we collected and reformate from `NetSurfP2`. The training and validation set are available at `data/utils`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SecondaryStructureAnnotatedDataset(f\"{UTILS}/training_set.pt\", 50)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 15, collate_fn = collate_sequences_train,\n",
    "                        shuffle = True, drop_last=True)\n",
    "\n",
    "val_dataset = SecondaryStructureAnnotatedDataset(f\"{UTILS}/validation_set.pt\", 50)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 15, collate_fn = collate_sequences_train,\n",
    "                        shuffle=False, drop_last=False)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model = NetSurfP2(50, name=\"netsurp2\")\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then train, 5 epochs should be enough with these parameters to reach a palier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc = 0\n",
    "for i in range(5):\n",
    "    model.train_epoch(train_loader, optimizer, i)\n",
    "    mean_ss3_acc, _ = model.val_epoch(val_loader, i)\n",
    "    if mean_ss3_acc > max_acc:\n",
    "        torch.save(model.state_dict(), f\"{UTILS}/nsp2_50feats.h5\")\n",
    "        max_acc = mean_ss3_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting\n",
    "\n",
    "Once training is done, model is then ready for use. We load a dataset using `SSQAData_SSinf` and `collate_sequences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dataset = SSQAData_SSinf(f\"{PFAM_DATA}/{DATASET}/data.pt\")\n",
    "loader = DataLoader(dataset, batch_size = batch_size, \n",
    "                          shuffle = False, drop_last=False, collate_fn = collate_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ss = NetSurfP2(50, \"nsp\")\n",
    "model_ss = model_ss.to(device)\n",
    "optimizer = optim.Adam(model_ss.parameters(), lr=0.001)\n",
    "model_ss.load_state_dict(torch.load(f\"{UTILS}/nsp2_50feats.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss3 = torch.zeros(len(dataset), 3, 100)\n",
    "ss8 = torch.zeros(len(dataset), 8, 100)\n",
    "\n",
    "for batch_idx, data in enumerate(loader):\n",
    "    x = torch.tensor(data[0]).float().cuda()\n",
    "    _, s8, s3 = model_ss(x)\n",
    "    ss_ = F.softmax(s3,1).detach().cpu()\n",
    "    ss3[batch_size*batch_idx: batch_size*(batch_idx+1), :, :ss_.size(-1)] = ss_\n",
    "    ss_ = F.softmax(s8,1).detach().cpu()\n",
    "    ss8[batch_size*batch_idx: batch_size*(batch_idx+1), :, :ss_.size(-1)] = ss_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - SSQA\n",
    "\n",
    "For an overview of how to handle, please refer to `Chorismate Mutase - Russ et al. 2020` notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Restricted Boltzman Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgm.layers import OneHotLayer, GaussianLayer\n",
    "from pgm.model import MRF\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available :  seq L cluster_index weights subset seq_hmm pattern\n",
      "Available :  seq L cluster_index weights subset seq_hmm pattern\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SSQAData_RBM(f\"{PFAM_DATA}/{DATASET}/data.pt\", subset = \"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size = 100, shuffle = True)\n",
    "\n",
    "val_dataset = SSQAData_RBM(f\"{PFAM_DATA}/{DATASET}/data.pt\", subset = \"val\")\n",
    "val_loader = DataLoader(val_dataset, batch_size = 100, shuffle = False)\n",
    "\n",
    "batch_size, q, N = train_dataset.seqs.size()\n",
    "lamb_l1b = 0.25\n",
    "gamma = lamb_l1b/(2*q*N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pots = torch.zeros(q+1, N)\n",
    "for v, w in train_dataset:\n",
    "    pots += w*v\n",
    "pots /= torch.sum(train_dataset.weights)\n",
    "pots = (pots-pots.mean(0)[None]).view(-1).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visible_layers = [\"sequence\"]\n",
    "hidden_layers = [\"hidden\"]\n",
    "\n",
    "v = OneHotLayer(pots, N=N, q=q+1, name=\"sequence\")\n",
    "h = GaussianLayer(N=200, name=\"hidden\")\n",
    "\n",
    "E = [(v.name, h.name)]\n",
    "\n",
    "model_rbm = MRF(layers = {v.name: v,\n",
    "                    h.name: h}, edges = E, name = \"\")\n",
    "\n",
    "for visible in visible_layers:\n",
    "    edge = model_rbm.get_edge(visible, \"hidden\")\n",
    "    edge.gauge = edge.gauge.to(device)\n",
    "    \n",
    "optimizer = optim.Adam(model_rbm.parameters(), lr=0.001)\n",
    "\n",
    "#model.load(f\"{DATA}/{DATASET}/weights/seq-reg-200_4320.h5\")\n",
    "#model.ais(n_inter = 2000, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [100%] || Time: 0 min 33 || Loss: 5.891 || Reg: 2.334 || Acc: 0.690\n",
      "Train Epoch: 0 [100%] || Time: 0 min 33 || Loss: 5.891 || Reg: 2.334 || Acc: 0.690\n",
      "Val Epoch: 0 [100%] || Time: 0 min 8 || P(v): -1.308 || P(v,h): -6.039 || Acc: 0.692\n",
      "Train Epoch: 1 [100%] || Time: 0 min 32 || Loss: 6.307 || Reg: 1.812 || Acc: 0.753\n",
      "Train Epoch: 2 [92%] || Time: 0 min 29 || Loss: 6.477 || Reg: 2.243 || Acc: 0.780\r"
     ]
    }
   ],
   "source": [
    "for epoch in range(40000):\n",
    "    model_rbm.train_epoch(optimizer, train_loader, visible_layers, hidden_layers, [gamma], epoch,\n",
    "          savepath=f\"{PFAM_DATA}/{DATASET}/weights/seq-reg-200\")\n",
    "    if not epoch % 30:\n",
    "        model_rbm.val(val_loader, visible_layers, hidden_layers, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Sampling with RBM and SSQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `RBMSampling_With_SSQA.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
