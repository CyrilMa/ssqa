{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, random, warnings, subprocess, torch\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from data.mutation_data import run_family, run_dataset\n",
    "\n",
    "from ss_inference import NetSurfP2\n",
    "\n",
    "from ssqa import *\n",
    "\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from config import *\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "PATH = \"/home/malbranke/data/mut\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_family(fam, uniprotid):\n",
    "    print(f\"Starting with family {fam} (Uniprot ID : {uniprotid})\")\n",
    "    _, _ = run_family(PATH, fam, uniprotid)\n",
    "    print(\"Success\")\n",
    "    return\n",
    "\n",
    "def best_temperature(X, y):\n",
    "    e, dpunsup, pmunsup, dpsup, pmsup = X\n",
    "    print(e, dpunsup, pmunsup, dpsup, pmsup)\n",
    "    clf = LinearRegression(fit_intercept=False)\n",
    "    clf.fit(torch.cat([e[:,None],dpunsup[:,None],pmunsup[:,None]],1),y)\n",
    "    a,b,c = clf.coef_[0], clf.coef_[1], clf.coef_[2]\n",
    "    if a < 0:\n",
    "        Wunsup = 0,-b/a,-c/a\n",
    "    else:\n",
    "        Wunsup = 1,b/a,c/a\n",
    "    clf.fit(torch.cat([e[:,None],dpsup[:,None],pmsup[:,None]],1),y)\n",
    "    a,b,c = clf.coef_[0], clf.coef_[1], clf.coef_[2]\n",
    "    if a < 0:\n",
    "        Wsup = 0,-b/a,-c/a\n",
    "    else:\n",
    "        Wsup = 1,b/a,c/a\n",
    "    return Wunsup, Wsup\n",
    "\n",
    "def cv_spearmanr(ssqa, edca, dp, pm, y, N = 5):\n",
    "    cv = KFold(n_splits=N, shuffle=True)\n",
    "    rho_scores = {\"E\":0, \"sup/DP\":0, \"sup/PM\":0, \"sup/PM+DP\":0, \"sup/E+DP\":0, \"sup/E+PM\":0, \"sup/E+DP+PM\":0,\n",
    "                  \"unsup/DP\":0, \"unsup/PM\":0, \"unsup/PM+DP\":0, \"unsup/E+DP\":0, \"unsup/E+PM\":0, \"unsup/E+DP+PM\":0}\n",
    "    for i, (train_index, test_index) in enumerate(cv.split(edca)):\n",
    "        ssqa.train(dp[train_index], pm[train_index], y[train_index])\n",
    "        e = torch.tensor(edca[test_index])\n",
    "        dpunsup, pmunsup, dpsup, pmsup = ssqa.predict(dp[test_index], pm[test_index])\n",
    "        y_test = y[test_index]\n",
    "        (wu_e, wu_dp, wu_pm), (ws_e, ws_dp, ws_pm) = best_temperature([e, dpunsup, pmunsup, torch.tensor(dpsup), torch.tensor(pmsup)], y_test)\n",
    "\n",
    "        rho_scores[\"E\"] += np.abs(spearmanr(y_test, e))/N\n",
    "\n",
    "        rho_scores[\"sup/DP\"] += np.abs(spearmanr(y_test, dpsup)[0])/N\n",
    "        rho_scores[\"sup/PM\"] += np.abs(spearmanr(y_test, pmsup)[0])/N\n",
    "        rho_scores[\"sup/PM+DP\"] += np.abs(spearmanr(y_test, ws_dp * dpsup + ws_pm * pmsup)[0])/N\n",
    "        rho_scores[\"sup/E+DP\"] += np.abs(spearmanr(y_test, ws_e * e + ws_dp * dpsup)[0])/N\n",
    "        rho_scores[\"sup/E+PM\"] += np.abs(spearmanr(y_test, ws_e * e + ws_pm * pmsup)[0])/N\n",
    "        rho_scores[\"sup/E+DP+PM\"] += np.abs(spearmanr(y_test, ws_e * e + ws_dp * dpsup + ws_pm * pmsup)[0])/N\n",
    "\n",
    "        rho_scores[\"unsup/DP\"] += np.abs(spearmanr(y_test, dpunsup)[0])/N\n",
    "        rho_scores[\"unsup/PM\"] += np.abs(spearmanr(y_test, pmunsup)[0])/N\n",
    "        rho_scores[\"unsup/PM+DP\"] += np.abs(spearmanr(y_test, wu_dp * dpunsup + wu_pm * pmunsup)[0])/N\n",
    "        rho_scores[\"unsup/E+DP\"] += np.abs(spearmanr(y_test, wu_e * e + ws_dp * dpunsup)[0])/N\n",
    "        rho_scores[\"unsup/E+PM\"] += np.abs(spearmanr(y_test, wu_e * e + ws_pm * pmunsup)[0])/N\n",
    "        rho_scores[\"unsup/E+DP+PM\"] += np.abs(spearmanr(y_test, wu_e * e + wu_dp * dpunsup + wu_pm * pmunsup)[0])/N\n",
    "    return rho_scores\n",
    "\n",
    "def build_metrics():\n",
    "    for metadata in meta_df.itertuples():\n",
    "        family = metadata.family\n",
    "        name_dataset = metadata.dataset\n",
    "        uniprotid = metadata.uniprot\n",
    "        in_pdb = metadata.in_PDB\n",
    "        exp_columns = re.findall(r\"\\w\\w*\", metadata.exp_columns)\n",
    "        print(f\"Family : {family}\")\n",
    "        print(f\"Dataset : {name_dataset}\")\n",
    "        print(f\"Uniprot ID : {uniprotid}\")\n",
    "        print(f\"Experimental Columns : {exp_columns}\")\n",
    "        print()\n",
    "        directory = os.listdir(f\"{PATH}/{family}\")\n",
    "        if f\"{family}.fasta\" not in directory or f\"{family}_{name_dataset}.csv\" not in directory:\n",
    "            print(\"Missing files\")\n",
    "        if \"data.pt\" not in directory:\n",
    "            build_family(family, uniprotid)\n",
    "        if f\"{name_dataset}_data.pt\" not in directory:\n",
    "            run_dataset(PATH, family, name_dataset)\n",
    "        dataset = SSQAData_QA(f\"{PATH}/{family}/data.pt\")\n",
    "        pattern = dataset.c_pattern3, dataset.n_pattern3, dataset.c_pattern8, dataset.n_pattern8\n",
    "        dataset = SSQAData_QA(f\"{PATH}/{family}/{name_dataset}_data.pt\")\n",
    "        model_ss = NetSurfP2(50, \"nsp2\")\n",
    "        model_ss = model_ss.to(\"cuda\")\n",
    "        model_ss.load_state_dict(torch.load(f\"{UTILS}/nsp_50feats.h5\"))\n",
    "\n",
    "        seq_hmm = dataset.seq_hmm\n",
    "        size = seq_hmm.size(-1)\n",
    "\n",
    "        SS_HMM3 = torch.ones(3, size)/3\n",
    "        SS_HMM8 = torch.ones(8, size)/8\n",
    "        ss_hmm = torch.tensor(dataset[0]).float()\n",
    "        active_idx = torch.where((ss_hmm[:20].sum(0) > 0))[0]\n",
    "        pred = model_ss(ss_hmm[None, :, active_idx].cuda())\n",
    "        SS_HMM3[:, active_idx] = F.softmax(pred[2][0], 0).cpu()\n",
    "        SS_HMM8[:, active_idx] = F.softmax(pred[1][0], 0).cpu()\n",
    "        SS_HMM3 = SS_HMM3[None]\n",
    "        SS_HMM8 = SS_HMM8[None]\n",
    "        X = torch.cat([data[None] for data in dataset], 0)\n",
    "        ssqa = SSQAMut(model_ss, pattern, seq_hmm, SS_HMM3, SS_HMM8)\n",
    "\n",
    "        dp, pm = ssqa.featuring(X)\n",
    "        mut_df = pd.read_csv(f\"{MUT_DATA}/{family}/{name_dataset}_mutation_sequences.csv\", index_col=0)\n",
    "        isna = (mut_df[\"effect_prediction_epistatic\"].isna()) | (mut_df[\"effect_prediction_independent\"].isna())\n",
    "        for exp in exp_columns:\n",
    "            isnaexp = (mut_df[exp].isna()) | isna\n",
    "            y = mut_df[~isnaexp][exp].values\n",
    "            edca = torch.tensor(mut_df[\"effect_prediction_epistatic\"][~isnaexp]).float()\n",
    "            eind = torch.tensor(mut_df[\"effect_prediction_independent\"][~isnaexp]).float()\n",
    "            rho_scores_ind = cv_spearmanr(ssqa, eind, dp, pm, y)\n",
    "            rho_scores_dca = cv_spearmanr(ssqa, edca, dp, pm, y)\n",
    "\n",
    "            print(\"\")\n",
    "            print(f\"Size : {len(y)}\")\n",
    "            print(f\"Length : {size}\")\n",
    "            for k, v in rho_scores_dca.items():\n",
    "                print(f\"{k} : {v:.3f}\")\n",
    "            entry = [family, name_dataset, exp, uniprotid, in_pdb, size, len(y)]\n",
    "            entry += list(rho_scores_ind.values())\n",
    "            entry += list(rho_scores_dca.values())\n",
    "\n",
    "            rho_df = pd.read_csv(f\"{PATH}/rho_df.csv\", index_col = 0)\n",
    "            rho_df.loc[f\"{name_dataset}_{exp}\"] = entry\n",
    "            rho_df.to_csv(f\"{PATH}/rho_df.csv\")\n",
    "            print(\"\")\n",
    "    print(\"---------------------------\")\n",
    "    \n",
    "build_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_excel(f\"{PATH}/meta.xlsx\", index_col=0)\n",
    "rho_df = pd.DataFrame(columns = [\"fam\", \"dataset\", \"exp\", \"uniprotid\", \"inpdb\", \"length\", \"size\", \"ind/E\",\n",
    "                                 \"ind/sup/DP\", \"ind/sup/PM\", \"ind/sup/PM+DP\", \"ind/sup/E+DP\", \"ind/sup/E+PM\", \"ind/sup/E+DP+PM\",\n",
    "                                 \"ind/unsup/DP\", \"ind/unsup/PM\", \"ind/unsup/PM+DP\", \"ind/unsup/E+DP\", \"ind/unsup/E+PM\", \"ind/unsup/E+DP+PM\", \"dca/E\",\n",
    "                                 \"dca/sup/DP\", \"dca/sup/PM\", \"dca/sup/PM+DP\", \"dca/sup/E+DP\", \"dca/sup/E+PM\", \"dca/sup/E+DP+PM\",\n",
    "                                 \"dca/unsup/DP\", \"dca/unsup/PM\", \"dca/unsup/PM+DP\", \"dca/unsup/E+DP\", \"dca/unsup/E+PM\", \"dca/unsup/E+DP+PM\"\n",
    "                                 ])\n",
    "rho_df.to_csv(f\"{PATH}/rho_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10462776733243283"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.8 * 0.1 + 0.8 * 0.1 + 0.1 * 0.1)/(2*(.8*.8+2*.01)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\"fam\", \"dataset\", \"exp\", \"uniprotid\", \"inpdb\", \"length\", \"size\", \"ind/E\",\n",
    "                                 \"ind/sup/DP\", \"ind/sup/PM\", \"ind/sup/PM+DP\", \"ind/sup/E+DP\", \"ind/sup/E+PM\", \"ind/sup/E+DP+PM\",\n",
    "                                 \"ind/unsup/DP\", \"ind/unsup/PM\", \"ind/unsup/PM+DP\", \"ind/unsup/E+DP\", \"ind/unsup/E+PM\", \"ind/unsup/E+DP+PM\", \"dca/E\",\n",
    "                                 \"dca/sup/DP\", \"dca/sup/PM\", \"dca/sup/PM+DP\", \"dca/sup/E+DP\", \"dca/sup/E+PM\", \"dca/sup/E+DP+PM\",\n",
    "                                 \"dca/unsup/DP\", \"dca/unsup/PM\", \"dca/unsup/PM+DP\", \"dca/unsup/E+DP\", \"dca/unsup/E+PM\", \"dca/unsup/E+DP+PM\"\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = [family, name_dataset, exp, uniprotid, in_pdb, size, len(y)]\n",
    "entry += list(rho_scores_ind.values())\n",
    "entry += list(rho_scores_dca.values())\n",
    "\n",
    "rho_df = pd.read_csv(f\"{PATH}/rho_df.csv\", index_col = 0)\n",
    "rho_df.loc[f\"{name_dataset}_{exp}\"] = entry\n",
    "rho_df.to_csv(f\"{PATH}/rho_df.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
