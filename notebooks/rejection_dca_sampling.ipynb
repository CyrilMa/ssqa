{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from config import *\n",
    "\n",
    "DATASET = \"PF00296\"\n",
    "sys.path.append(f\"{ROOT}\")\n",
    "device = \"cpu\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from ss_inference.data import SecondaryStructureRawDataset\n",
    "from ss_inference.model import NetSurfP2\n",
    "from ss_inference.utils import *\n",
    "\n",
    "from config import DATA\n",
    "from pgm.data import SequenceData\n",
    "from pgm.layers import GaussianLayer, OneHotLayer\n",
    "from pgm.edge import Edge\n",
    "from pgm.model import MRF\n",
    "from pgm.utils import *\n",
    "\n",
    "from pattern_matching.loss import PatternMatchingLoss, QuickPatternMatchingLoss\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCA Rejection Sampling\n",
    "\n",
    "https://en.wikipedia.org/wiki/Rejection_sampling\n",
    "\n",
    "### Independant model\n",
    "\n",
    "Let's consider an independant model such that $E(x) = \\sum_i g_i(x_i) = g(x)$. We want to extend it to include secondary structure QA. We consider $r$ a pattern a $R$ the set of secondary structure matching pattern $r$.\n",
    "$$M(x) = \\sum_{s \\in R} \\mathbb P(s|x)$$\n",
    "\n",
    "Then $m(x) = - \\log(M(x))$. We can then establish that $E(x) = g(x) + m(x)$. If we want to weight the two value we set $E$ to be $E(x) = g(x) + \\frac{1}{T} m(x)$. We then have :\n",
    "\n",
    "$$\\mathbb{P}(x) = \\frac{1}{Z} G(x)M(x)^{1/T}$$\n",
    "\n",
    "How do we sample according to this probability ? Sampling with G(x) is easy but $M(x)$ is not invertible. We rely on rejection sampling.\n",
    "\n",
    "To do this we sample following to the process :\n",
    "- We sample $X$ according to $G(x)$ and $U$ according to a unifrom distrbituion in $[0,1]$\n",
    "- if $M(X)^{1/T} < U$ we accept the sample, else we reject the sample and go back to step 1\n",
    "\n",
    "We then have :\n",
    "$$\\mathbb{P}(X = x) \\propto G(x)M(x)^{1/T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SS3 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetSurfP2(\n",
       "  (conv1): ResBlock(\n",
       "    (conv_1): ConvBlock(\n",
       "      (conv): Conv1d(50, 32, kernel_size=(129,), stride=(1,), padding=(64,))\n",
       "      (activation): LeakyReLU(negative_slope=0.2)\n",
       "      (normalization): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): ConvBlock(\n",
       "      (conv): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
       "      (normalization): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): ResBlock(\n",
       "    (conv_1): ConvBlock(\n",
       "      (conv): Conv1d(32, 32, kernel_size=(257,), stride=(1,), padding=(128,))\n",
       "      (activation): LeakyReLU(negative_slope=0.2)\n",
       "      (normalization): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv2): ConvBlock(\n",
       "      (conv): Conv1d(32, 32, kernel_size=(1,), stride=(1,))\n",
       "      (normalization): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (lstm1): LSTM(82, 1024, bidirectional=True)\n",
       "  (lstm2): LSTM(2048, 1024, bidirectional=True)\n",
       "  (conv_other): ConvBlock(\n",
       "    (conv): Conv1d(2048, 9, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (conv_ss8): ConvBlock(\n",
       "    (conv): Conv1d(2048, 8, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (conv_ss3): ConvBlock(\n",
       "    (conv): Conv1d(2048, 3, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ss3 = NetSurfP2(50)\n",
    "optimizer = optim.Adam(model_ss3.parameters(), lr=0.001)\n",
    "model_ss3.load_state_dict(torch.load(f\"{DATA}/secondary_structure/lstm_50feats.h5\"))\n",
    "model_ss3.eval()\n",
    "model_ss3 = model_ss3.to(\"cuda\")\n",
    "\n",
    "model_ss3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequenceData(f\"{DATA}/{DATASET}\", dataset=\"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size = 30, \n",
    "                          shuffle = True, drop_last = True)\n",
    "\n",
    "val_dataset = SequenceData(f\"{DATA}/{DATASET}\", dataset=\"val\")\n",
    "val_loader = DataLoader(val_dataset, batch_size = 30, drop_last = True)\n",
    "\n",
    "N, qv = train_dataset.raw_sequences.shape[1], train_dataset.raw_sequences.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "independant = np.zeros((train_dataset.raw_sequences.shape[1], train_dataset.raw_sequences.shape[2]))\n",
    "for w, v in zip(train_dataset.weights,train_dataset.raw_sequences):\n",
    "    independant += w*v\n",
    "independant /= np.sum(train_dataset.weights)\n",
    "independant = torch.FloatTensor(independant).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.one_hot_categorical import OneHotCategorical\n",
    "\n",
    "independant_sampler = OneHotCategorical(independant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pots = np.zeros((train_dataset.raw_sequences.shape[1], train_dataset.raw_sequences.shape[2]))\n",
    "for w, v in zip(train_dataset.weights,train_dataset.raw_sequences):\n",
    "    pots += w*v\n",
    "pots /= np.sum(train_dataset.weights)\n",
    "pots = pots.T\n",
    "pots = torch.FloatTensor((pots.T-np.mean(pots, 1)).T).reshape(-1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "ais() got an unexpected keyword argument 'n_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3482ea9c7071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{DATA}/{DATASET}/weights/seq-reg-1000_150.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mais\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ais() got an unexpected keyword argument 'n_iter'"
     ]
    }
   ],
   "source": [
    "visible_layers = [\"sequence\"]\n",
    "hidden_layers = [\"hidden\"]\n",
    "\n",
    "v = OneHotLayer(pots, N=N, q=qv, name=\"sequence\")\n",
    "h = GaussianLayer(N=1000, name=\"hidden\")\n",
    "\n",
    "E = [(v.name, h.name)]\n",
    "\n",
    "model1 = MRF(layers={v.name: v,\n",
    "                    h.name: h},\n",
    "            edges=E)\n",
    "\n",
    "for visible in visible_layers:\n",
    "    edge = model1.get_edge(visible, \"hidden\")\n",
    "    \n",
    "model1.load(f\"{DATA}/{DATASET}/weights/seq-reg-1000_150.h5\")\n",
    "model1.ais(n_inter = 20000, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : -4.272460864740424e-05\n",
      "Iteration 2000 : 119.15225828495113\n",
      "Iteration 4000 : 508.3628956010589\n",
      "Iteration 6000 : 1230.5273480048427\n",
      "Iteration 8000 : 2345.0913991859206\n",
      "Iteration 10000 : 3924.5064020087966\n",
      "Iteration 12000 : 6041.8340753247985\n",
      "Iteration 14000 : 8729.372380130553\n",
      "Iteration 16000 : 11986.189762585425\n",
      "Iteration 18000 : 15800.490837328696\n",
      "Estimated Z : 17.440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.440141677856445"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.ais(n_inter = 20000, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def rejection_sampling(model, matcher, n_samples, T, visible_layers = None, hidden_layers = None):\n",
    "    samples = []\n",
    "    while(True):\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            print(f\"{len(samples)}/{n_samples} [{int(100*len(samples)/n_samples)}%]\", end=\"\\r\")\n",
    "            if model == \"natural\":\n",
    "                x = data[0].permute(0,2,1)\n",
    "            elif model == \"independant\":\n",
    "                x = independant_sampler.sample_n(200).permute(0,2,1)\n",
    "            else:\n",
    "                d_0 = {k: v.float().permute(0, 2, 1).to(device) for k, v in zip(LAYERS_NAME, data[:1]) if k in visible_layers}\n",
    "                batch_size, q, N = d_0[\"sequence\"].size()\n",
    "                _, d_f = model.gibbs_sampling(d_0, visible_layers, hidden_layers, k=30)\n",
    "                x = d_f[\"sequence\"]\n",
    "            mx = matcher(x).detach()\n",
    "            print(np.exp(mx))\n",
    "            for x_, mx_ in zip(x, mx):\n",
    "                if len(samples) >= n_samples:\n",
    "                    return samples\n",
    "                thr = np.exp(mx_/T)\n",
    "                if random() < thr:\n",
    "                    samples.append((x_, -mx_))\n",
    "                    \n",
    "def local_rejection_sampling(model, matcher, n_samples, T, visible_layers = None, hidden_layers = None):\n",
    "    samples = []\n",
    "    while(True):\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            print(f\"{len(samples)}/{n_samples} [{int(100*len(samples)/n_samples)}%]\", end=\"\\r\")\n",
    "            if model == \"natural\":\n",
    "                x = data[0].permute(0,2,1)\n",
    "            elif model == \"independant\":\n",
    "                x = independant_sampler.sample_n(200).permute(0,2,1)\n",
    "            else:\n",
    "                d_0 = {k: v.float().permute(0, 2, 1).to(device) for k, v in zip(LAYERS_NAME, data[:1]) if k in visible_layers}\n",
    "                batch_size, q, N = d_0[\"sequence\"].size()\n",
    "                _, d_f = model.gibbs_sampling(d_0, visible_layers, hidden_layers, k=30)\n",
    "                x = d_f[\"sequence\"]\n",
    "            mx = matcher(x).detach()\n",
    "            print(np.exp(mx))\n",
    "            for x_, mx_ in zip(x, mx):\n",
    "                if len(samples) >= n_samples:\n",
    "                    return samples\n",
    "                thr = np.exp(mx_/T)\n",
    "                if random() < thr:\n",
    "                    samples.append((x_, -mx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_hmm = torch.tensor(dataset[0][3]).t()[20:]\n",
    "torch.save(seq_hmm, f\"{DATA}/{DATASET}/hmm.pt\")\n",
    "_, size = seq_hmm.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patterns, c_patterns, _ =  pickle.load(open(f\"{DATA}/{DATASET}/patterns.pkl\",\"rb\"))\n",
    "regexes = []\n",
    "for x in n_patterns:\n",
    "    if len(x):\n",
    "        regexes.append([(i,None,None) for i in x])\n",
    "size = 150\n",
    "Q = np.ones((3, size+1, size+1)) * (-np.inf)\n",
    "e = size\n",
    "for i in range(size+1):\n",
    "    Q[:3, i, i+1:] = 0\n",
    "Q = Q.reshape(1, *Q.shape)\n",
    "\n",
    "ss_hmm = pickle.load(open(f\"{DATA}/{DATASET}/ss_profile.pkl\", \"rb\"))\n",
    "seq_hmm = torch.load(f\"{DATA}/{DATASET}/hmm.pt\")\n",
    "\n",
    "matcher = PatternMatching(model_ss3, pattern = regexes[1], Q = Q ,\n",
    "                          seq_hmm = seq_hmm, ss_hmm = ss_hmm, \n",
    "                          size = size, name = c_patterns[1])\n",
    "#matcher = PatternMatchingLoss(model_ss3, pattern = regexes[0], Q = Q, seq_hmm = seq_hmm, ss_hmm = ss_hmm, size = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7354, 0.7718, 0.6820, 0.6671, 0.7183, 0.6941, 0.7014, 0.7169, 0.7812,\n",
      "        0.7370, 0.7475, 0.6771, 0.7235, 0.6756, 0.7149, 0.6975, 0.7089, 0.6988,\n",
      "        0.6930, 0.7297, 0.7222, 0.7059, 0.7098, 0.7069, 0.7146, 0.7847, 0.6974,\n",
      "        0.6991, 0.7002, 0.7040])\n",
      "tensor([0.7699, 0.7409, 0.6832, 0.6807, 0.7086, 0.6935, 0.7592, 0.6121, 0.6854,\n",
      "        0.7837, 0.7203, 0.5688, 0.7937, 0.6737, 0.7879, 0.7209, 0.7049, 0.6896,\n",
      "        0.7102, 0.7150, 0.7094, 0.7259, 0.7352, 0.7319, 0.7699, 0.6904, 0.7549,\n",
      "        0.7279, 0.7598, 0.7264])\n",
      "tensor([0.7205, 0.7658, 0.6820, 0.7312, 0.7649, 0.7033, 0.7256, 0.7251, 0.6905,\n",
      "        0.7726, 0.7069, 0.7450, 0.7217, 0.7239, 0.7181, 0.7295, 0.7203, 0.7430,\n",
      "        0.7196, 0.7044, 0.7012, 0.7030, 0.7198, 0.7076, 0.6707, 0.6984, 0.7071,\n",
      "        0.4122, 0.7084, 0.6644])\n",
      "tensor([0.7426, 0.6842, 0.7235, 0.7346, 0.7281, 0.6974, 0.7406, 0.5405, 0.6820,\n",
      "        0.7594, 0.7042, 0.7132, 0.6883, 0.7029, 0.6784, 0.7295, 0.7326, 0.7656,\n",
      "        0.7213, 0.7292, 0.7031, 0.6534, 0.7082, 0.6916, 0.7117, 0.7018, 0.7505,\n",
      "        0.6977, 0.7693, 0.7848])\n",
      "tensor([0.6974, 0.7808, 0.6799, 0.7138, 0.7121, 0.7564, 0.7279, 0.6835, 0.6892,\n",
      "        0.7062, 0.7207, 0.6712, 0.6787, 0.7077, 0.7032, 0.7198, 0.7875, 0.7050,\n",
      "        0.6527, 0.7029, 0.6956, 0.7080, 0.7107, 0.7029, 0.7232, 0.6586, 0.7182,\n",
      "        0.7215, 0.7261, 0.7092])\n",
      "tensor([0.7338, 0.7187, 0.7686, 0.7688, 0.7362, 0.6742, 0.7255, 0.7245, 0.7048,\n",
      "        0.7146, 0.6798, 0.7017, 0.7123, 0.7171, 0.5763, 0.7728, 0.7097, 0.7112,\n",
      "        0.7249, 0.7356, 0.6467, 0.7041, 0.7266, 0.5932, 0.6827, 0.6964, 0.7009,\n",
      "        0.3904, 0.6930, 0.7560])\n",
      "tensor([0.6518, 0.7229, 0.7129, 0.6978, 0.7402, 0.6731, 0.7142, 0.6687, 0.7273,\n",
      "        0.7225, 0.7714, 0.7216, 0.6668, 0.6890, 0.6853, 0.7022, 0.6729, 0.7207,\n",
      "        0.7241, 0.7222, 0.7174, 0.7186, 0.7092, 0.7039, 0.7720, 0.7691, 0.6520,\n",
      "        0.7210, 0.6860, 0.7043])\n",
      "tensor([0.7177, 0.7647, 0.7326, 0.6880, 0.7794, 0.7283, 0.7818, 0.7313, 0.7609,\n",
      "        0.7154, 0.7052, 0.7178, 0.5035, 0.7746, 0.7404, 0.7727, 0.7081, 0.7769,\n",
      "        0.6788, 0.7524, 0.7402, 0.7819, 0.7385, 0.3401, 0.7343, 0.7052, 0.7317,\n",
      "        0.6982, 0.6966, 0.7319])\n",
      "tensor([0.7023, 0.7624, 0.7139, 0.7701, 0.7649, 0.7892, 0.7680, 0.6852, 0.7433,\n",
      "        0.7206, 0.7121, 0.7083, 0.7061, 0.7825, 0.6918, 0.7316, 0.4265, 0.6912,\n",
      "        0.6991, 0.7668, 0.7637, 0.7809, 0.6926, 0.6914, 0.7041, 0.7268, 0.7841,\n",
      "        0.7068, 0.7067, 0.6832])\n",
      "tensor([0.5973, 0.3867, 0.7200, 0.6809, 0.7027, 0.6269, 0.7027, 0.6901, 0.7429,\n",
      "        0.5512, 0.7300, 0.7233, 0.7047, 0.6978, 0.7711, 0.7199, 0.7751, 0.7431,\n",
      "        0.6998, 0.3947, 0.7452, 0.6901, 0.7143, 0.7169, 0.7000, 0.7476, 0.7191,\n",
      "        0.7218, 0.6751, 0.6985])\n",
      "tensor([0.6834, 0.7402, 0.7257, 0.7500, 0.7113, 0.7273, 0.7153, 0.7182, 0.7586,\n",
      "        0.7084, 0.6915, 0.6744, 0.7090, 0.6929, 0.7008, 0.7397, 0.7391, 0.7018,\n",
      "        0.7176, 0.7842, 0.7029, 0.7642, 0.7179, 0.6953, 0.6990, 0.7037, 0.7819,\n",
      "        0.7114, 0.7088, 0.7620])\n",
      "tensor([0.6955, 0.7452, 0.7089, 0.6931, 0.7206, 0.7138, 0.6692, 0.6595, 0.7184,\n",
      "        0.7038, 0.6897, 0.4626, 0.6756, 0.7644, 0.7151, 0.6715, 0.7306, 0.6831,\n",
      "        0.4752, 0.7405, 0.7292, 0.7094, 0.7230, 0.7046, 0.6995, 0.7735, 0.7069,\n",
      "        0.6904, 0.7147, 0.7309])\n",
      "tensor([0.7381, 0.6923, 0.7289, 0.7095, 0.7211, 0.7071, 0.7004, 0.3325, 0.7682,\n",
      "        0.7180, 0.7067, 0.7096, 0.7022, 0.7073, 0.7679, 0.6774, 0.7668, 0.7212,\n",
      "        0.6687, 0.7080, 0.6956, 0.7299, 0.4163, 0.7211, 0.7589, 0.6818, 0.7314,\n",
      "        0.7668, 0.7462, 0.7054])\n",
      "tensor([0.7022, 0.6813, 0.7159, 0.7002, 0.7684, 0.7295, 0.7082, 0.6829, 0.7000,\n",
      "        0.7201, 0.7247, 0.6953, 0.6711, 0.7456, 0.7510, 0.6986, 0.7170, 0.7400,\n",
      "        0.7160, 0.7187, 0.4418, 0.7793, 0.6883, 0.7133, 0.7911, 0.6845, 0.6786,\n",
      "        0.7107, 0.7099, 0.7056])\n",
      "tensor([0.7768, 0.7197, 0.7316, 0.7355, 0.7277, 0.7632, 0.7307, 0.7205, 0.6947,\n",
      "        0.7383, 0.7452, 0.6907, 0.7117, 0.7662, 0.6745, 0.7238, 0.6869, 0.6977,\n",
      "        0.7672, 0.7155, 0.7308, 0.7540, 0.7855, 0.7416, 0.7877, 0.6977, 0.7383,\n",
      "        0.7349, 0.6717, 0.7165])\n",
      "tensor([0.6989, 0.7418, 0.7340, 0.7515, 0.7305, 0.7111, 0.7309, 0.7124, 0.7705,\n",
      "        0.7159, 0.6161, 0.7394, 0.6042, 0.6305, 0.7250, 0.7445, 0.6905, 0.4072,\n",
      "        0.7151, 0.7839, 0.7306, 0.7076, 0.6566, 0.6892, 0.7120, 0.7269, 0.7430,\n",
      "        0.7481, 0.7129, 0.7235])\n",
      "tensor([0.6863, 0.7347, 0.6911, 0.5938, 0.7012, 0.7166, 0.7857, 0.7249, 0.7477,\n",
      "        0.7516, 0.7137, 0.7128, 0.7379, 0.7214, 0.7891, 0.7287, 0.7196, 0.7322,\n",
      "        0.3492, 0.7087, 0.5974, 0.7282, 0.7472, 0.7054, 0.6975, 0.6958, 0.6213,\n",
      "        0.7435, 0.7115, 0.3444])\n",
      "tensor([0.7151, 0.7215, 0.7129, 0.7239, 0.7392, 0.7289, 0.7382, 0.6925, 0.7422,\n",
      "        0.7854, 0.7029, 0.7148, 0.6976, 0.6696, 0.6892, 0.7012, 0.7172, 0.6927,\n",
      "        0.7155, 0.7395, 0.7116, 0.7843, 0.7252, 0.7031, 0.7161, 0.7271, 0.7296,\n",
      "        0.6530, 0.7414, 0.7521])\n",
      "tensor([0.7449, 0.7176, 0.7258, 0.7207, 0.3425, 0.8065, 0.7098, 0.7241, 0.6843,\n",
      "        0.7468, 0.6902, 0.7026, 0.7437, 0.7252, 0.7749, 0.7209, 0.7008, 0.7024,\n",
      "        0.6961, 0.6902, 0.6770, 0.7037, 0.7088, 0.7334, 0.7132, 0.7190, 0.7884,\n",
      "        0.7029, 0.7195, 0.7513])\n",
      "tensor([0.6896, 0.7148, 0.3031, 0.7684, 0.7309, 0.7272, 0.7270, 0.7681, 0.7097,\n",
      "        0.7234, 0.7726, 0.7279, 0.7214, 0.6990, 0.4437, 0.7122, 0.7252, 0.6842,\n",
      "        0.7192, 0.6907, 0.6459, 0.7161, 0.7559, 0.7162, 0.3413, 0.7182, 0.7371,\n",
      "        0.7139, 0.7009, 0.7403])\n",
      "tensor([0.7407, 0.7298, 0.7375, 0.7438, 0.7024, 0.7419, 0.7214, 0.7004, 0.7199,\n",
      "        0.7103, 0.6895, 0.6258, 0.7352, 0.7378, 0.7397, 0.7082, 0.7053, 0.6872,\n",
      "        0.7749, 0.7031, 0.7059, 0.7716, 0.7237, 0.6333, 0.7174, 0.3688, 0.7004,\n",
      "        0.7255, 0.7225, 0.7716])\n",
      "tensor([0.3658, 0.7280, 0.7193, 0.6935, 0.7452, 0.7099, 0.6988, 0.7482, 0.6982,\n",
      "        0.7377, 0.7556, 0.7306, 0.7759, 0.7064, 0.7483, 0.7246, 0.6877, 0.6764,\n",
      "        0.7458, 0.7266, 0.7222, 0.7556, 0.6647, 0.7085, 0.6731, 0.7592, 0.6884,\n",
      "        0.7159, 0.7135, 0.7159])\n",
      "tensor([0.7133, 0.7294, 0.7661, 0.6836, 0.7400, 0.7758, 0.7452, 0.6989, 0.7496,\n",
      "        0.7266, 0.6989, 0.6945, 0.7164, 0.7790, 0.6823, 0.7042, 0.7251, 0.7676,\n",
      "        0.7163, 0.6782, 0.7240, 0.7209, 0.6918, 0.6966, 0.7580, 0.6951, 0.7449,\n",
      "        0.7460, 0.7158, 0.6920])\n",
      "tensor([0.6756, 0.7659, 0.6718, 0.7019, 0.7492, 0.7367, 0.7341, 0.7339, 0.7136,\n",
      "        0.6936, 0.7136, 0.7095, 0.7116, 0.7435, 0.6946, 0.7708, 0.6865, 0.7808,\n",
      "        0.7009, 0.7798, 0.7328, 0.7052, 0.7914, 0.6764, 0.6163, 0.6979, 0.7054,\n",
      "        0.6823, 0.7134, 0.7204])\n",
      "tensor([0.4245, 0.7657, 0.7611, 0.7700, 0.6925, 0.7309, 0.7264, 0.7620, 0.7182,\n",
      "        0.7361, 0.7432, 0.7178, 0.7181, 0.7734, 0.7122, 0.7498, 0.7635, 0.6796,\n",
      "        0.7127, 0.7360, 0.7034, 0.7478, 0.7219, 0.7418, 0.6078, 0.7226, 0.7089,\n",
      "        0.7038, 0.7763, 0.7109])\n",
      "tensor([0.7263, 0.7792, 0.4979, 0.7238, 0.7063, 0.6969, 0.6998, 0.6623, 0.7737,\n",
      "        0.7869, 0.7392, 0.7077, 0.7407, 0.6976, 0.7038, 0.7429, 0.6984, 0.7330,\n",
      "        0.7381, 0.7387, 0.7763, 0.6855, 0.7243, 0.7093, 0.7656, 0.6965, 0.7023,\n",
      "        0.5986, 0.7638, 0.7299])\n",
      "tensor([0.7238, 0.7344, 0.7250, 0.7311, 0.7335, 0.6925, 0.7217, 0.7107, 0.6919,\n",
      "        0.7995, 0.6800, 0.7122, 0.4278, 0.3592, 0.7165, 0.7502, 0.6958, 0.7045,\n",
      "        0.7704, 0.6871, 0.7339, 0.7688, 0.7005, 0.7273, 0.7638, 0.7394, 0.7905,\n",
      "        0.6909, 0.7068, 0.4257])\n",
      "tensor([0.7236, 0.7214, 0.7250, 0.7326, 0.6976, 0.7373, 0.7763, 0.6922, 0.7015,\n",
      "        0.7131, 0.7165, 0.7038, 0.7177, 0.6958, 0.7528, 0.7105, 0.7309, 0.6716,\n",
      "        0.7373, 0.6961, 0.7032, 0.7132, 0.6922, 0.7215, 0.7245, 0.7453, 0.7603,\n",
      "        0.7092, 0.6958, 0.7242])\n",
      "tensor([0.7362, 0.6926, 0.7117, 0.6053, 0.7127, 0.7157, 0.7043, 0.6844, 0.7075,\n",
      "        0.7326, 0.6976, 0.7136, 0.7134, 0.7134, 0.7678, 0.7319, 0.7102, 0.7109,\n",
      "        0.6819, 0.7263, 0.7077, 0.3574, 0.7003, 0.7085, 0.7130, 0.7072, 0.7670,\n",
      "        0.6614, 0.6770, 0.7152])\n",
      "tensor([0.7569, 0.7237, 0.5907, 0.7060, 0.7144, 0.7004, 0.7648, 0.6931, 0.6673,\n",
      "        0.6811, 0.7306, 0.7256, 0.7466, 0.7115, 0.7122, 0.6799, 0.7888, 0.7678,\n",
      "        0.7402, 0.7262, 0.7630, 0.7425, 0.6945, 0.7436, 0.7114, 0.7115, 0.7335,\n",
      "        0.7199, 0.3705, 0.7352])\n",
      "tensor([0.7701, 0.7186, 0.7798, 0.6992, 0.7237, 0.7389, 0.6959, 0.6813, 0.7508,\n",
      "        0.7333, 0.7098, 0.7348, 0.7619, 0.7037, 0.7097, 0.7329, 0.7257, 0.7122,\n",
      "        0.7018, 0.7163, 0.7344, 0.6864, 0.7188, 0.7064, 0.7133, 0.2959, 0.7464,\n",
      "        0.7358, 0.7418, 0.6900])\n",
      "tensor([0.7454, 0.6903, 0.7264, 0.6758, 0.6821, 0.7151, 0.7056, 0.7061, 0.7140,\n",
      "        0.5995, 0.7295, 0.7669, 0.6983, 0.7127, 0.7302, 0.6894, 0.7740, 0.6884,\n",
      "        0.7102, 0.7263, 0.7138, 0.6291, 0.4975, 0.6926, 0.4675, 0.7672, 0.7182,\n",
      "        0.6895, 0.7254, 0.6935])\n",
      "tensor([0.7114, 0.6914, 0.7135, 0.6845, 0.7195, 0.6975, 0.4503, 0.7054, 0.7383,\n",
      "        0.6917, 0.7243, 0.6368, 0.7909, 0.7161, 0.6529, 0.7119, 0.7404, 0.7191,\n",
      "        0.7065, 0.7945, 0.7460, 0.7438, 0.7040, 0.7097, 0.7550, 0.7313, 0.7619,\n",
      "        0.7174, 0.7435, 0.6976])\n",
      "tensor([0.3341, 0.7017, 0.7520, 0.6014, 0.7114, 0.7005, 0.7648, 0.7136, 0.7253,\n",
      "        0.7265, 0.6810, 0.7326, 0.7242, 0.7313, 0.3877, 0.6924, 0.7022, 0.7866,\n",
      "        0.7483, 0.7233, 0.6833, 0.6441, 0.7327, 0.7214, 0.6990, 0.7392, 0.7106,\n",
      "        0.6020, 0.6462, 0.7943])\n",
      "tensor([0.7587, 0.6458, 0.7315, 0.7563, 0.7080, 0.7270, 0.7348, 0.7305, 0.7000,\n",
      "        0.7157, 0.7503, 0.5920, 0.7827, 0.7247, 0.6599, 0.7237, 0.7595, 0.7732,\n",
      "        0.6552, 0.7013, 0.7285, 0.7029, 0.6740, 0.7345, 0.7119, 0.7213, 0.7659,\n",
      "        0.7042, 0.7007, 0.6914])\n",
      "tensor([0.7000, 0.6053, 0.2906, 0.7141, 0.6884, 0.7089, 0.7226, 0.7130, 0.7103,\n",
      "        0.7763, 0.7855, 0.7101, 0.7665, 0.6814, 0.7625, 0.7176, 0.7860, 0.7387,\n",
      "        0.7168, 0.7112, 0.7198, 0.7317, 0.7032, 0.7107, 0.7199, 0.6771, 0.7271,\n",
      "        0.7353, 0.7150, 0.7089])\n",
      "tensor([0.7487, 0.7020, 0.7661, 0.7855, 0.7326, 0.7199, 0.7250, 0.6987, 0.7142,\n",
      "        0.7449, 0.7919, 0.7270, 0.7586, 0.6979, 0.7699, 0.6990, 0.7691, 0.7136,\n",
      "        0.7004, 0.6451, 0.6934, 0.7722, 0.7824, 0.7600, 0.7169, 0.7829, 0.7590,\n",
      "        0.7679, 0.7705, 0.7443])\n",
      "tensor([0.7694, 0.7206, 0.7869, 0.7080, 0.7511, 0.7704, 0.7199, 0.7722, 0.7131,\n",
      "        0.7035, 0.7084, 0.7202, 0.7258, 0.7325, 0.7161, 0.7415, 0.7048, 0.7014,\n",
      "        0.6889, 0.7041, 0.7785, 0.7059, 0.7126, 0.7396, 0.7063, 0.7223, 0.7015,\n",
      "        0.7116, 0.8009, 0.7295])\n",
      "tensor([0.7267, 0.6865, 0.7633, 0.7657, 0.7691, 0.7010, 0.7148, 0.6887, 0.6942,\n",
      "        0.7419, 0.7440, 0.7370, 0.7163, 0.7299, 0.6899, 0.6946, 0.7059, 0.7400,\n",
      "        0.7398, 0.6773, 0.6926, 0.7444, 0.7027, 0.7247, 0.7302, 0.7219, 0.7285,\n",
      "        0.6683, 0.6772, 0.6982])\n",
      "tensor([0.7077, 0.7224, 0.7163, 0.7213, 0.7719, 0.7153, 0.7058, 0.7276, 0.6825,\n",
      "        0.7166, 0.7086, 0.6993, 0.7396, 0.6933, 0.6602, 0.7751, 0.7159, 0.7360,\n",
      "        0.7120, 0.7423, 0.7289, 0.7480, 0.7348, 0.7074, 0.7416, 0.7043, 0.7169,\n",
      "        0.7093, 0.6886, 0.5768])\n",
      "tensor([0.7316, 0.7519, 0.6890, 0.6802, 0.7105, 0.5251, 0.6475, 0.7671, 0.7013,\n",
      "        0.7337, 0.7063, 0.7269, 0.7314, 0.7296, 0.7315, 0.6830, 0.7849, 0.7274,\n",
      "        0.7380, 0.7310, 0.7282, 0.6908, 0.7326, 0.7433, 0.7448, 0.7427, 0.6902,\n",
      "        0.7008, 0.7791, 0.6890])\n",
      "tensor([0.7128, 0.7408, 0.4170, 0.7127, 0.7550, 0.7140, 0.7494, 0.7297, 0.7481,\n",
      "        0.7312, 0.7051, 0.7499, 0.7126, 0.7638, 0.7131, 0.7046, 0.6926, 0.7051,\n",
      "        0.7329, 0.7876, 0.7598, 0.7128, 0.6434, 0.7316, 0.7359, 0.7486, 0.7780,\n",
      "        0.7104, 0.7355, 0.7113])\n",
      "tensor([0.6887, 0.4598, 0.7559, 0.7362, 0.7286, 0.6537, 0.7521, 0.7313, 0.7129,\n",
      "        0.7247, 0.5834, 0.7241, 0.6918, 0.6922, 0.7043, 0.6785, 0.7715, 0.6911,\n",
      "        0.7467, 0.5853, 0.7076, 0.6437, 0.6830, 0.7162, 0.7003, 0.6851, 0.7344,\n",
      "        0.7409, 0.7042, 0.7424])\n",
      "tensor([0.7235, 0.6772, 0.6620, 0.7248, 0.7306, 0.6402, 0.7854, 0.7523, 0.6692,\n",
      "        0.7260, 0.7344, 0.7322, 0.6846, 0.7413, 0.6325, 0.7347, 0.7031, 0.7102,\n",
      "        0.7195, 0.6721, 0.7010, 0.7070, 0.7310, 0.6403, 0.6985, 0.7131, 0.6869,\n",
      "        0.7210, 0.7212, 0.7114])\n",
      "tensor([0.7194, 0.6971, 0.7182, 0.6907, 0.7270, 0.7250, 0.7163, 0.6682, 0.7129,\n",
      "        0.7438, 0.7142, 0.7010, 0.7181, 0.7233, 0.7697, 0.7399, 0.7063, 0.7090,\n",
      "        0.7039, 0.7356, 0.6652, 0.5951, 0.7111, 0.7081, 0.7013, 0.7218, 0.5919,\n",
      "        0.6880, 0.7445, 0.7189])\n",
      "tensor([0.6805, 0.7723, 0.7719, 0.7269, 0.7075, 0.7121, 0.7002, 0.6859, 0.6902,\n",
      "        0.6987, 0.7209, 0.7319, 0.6970, 0.7290, 0.7009, 0.7224, 0.6561, 0.7035,\n",
      "        0.6928, 0.7742, 0.7388, 0.7150, 0.7146, 0.7653, 0.7213, 0.7354, 0.7042,\n",
      "        0.6779, 0.2142, 0.7511])\n",
      "tensor([0.7123, 0.6857, 0.7519, 0.7119, 0.7506, 0.6940, 0.2556, 0.7460, 0.6610,\n",
      "        0.7191, 0.7249, 0.6941, 0.7159, 0.7201, 0.7767, 0.7164, 0.7586, 0.6747,\n",
      "        0.7480, 0.7056, 0.7209, 0.4429, 0.6907, 0.7236, 0.6988, 0.7089, 0.2764,\n",
      "        0.7156, 0.7774, 0.7077])\n",
      "tensor([0.7641, 0.6970, 0.7101, 0.6987, 0.7447, 0.7769, 0.6956, 0.6644, 0.7603,\n",
      "        0.6966, 0.6350, 0.7069, 0.7178, 0.7000, 0.6739, 0.6906, 0.7086, 0.3304,\n",
      "        0.7200, 0.7131, 0.7040, 0.7273, 0.6779, 0.7864, 0.7037, 0.7395, 0.7227,\n",
      "        0.7114, 0.7370, 0.7034])\n",
      "tensor([0.6797, 0.7229, 0.7253, 0.7113, 0.7735, 0.7174, 0.7229, 0.7121, 0.7207,\n",
      "        0.6823, 0.7475, 0.4332, 0.7228, 0.7285, 0.7394, 0.6856, 0.7243, 0.7703,\n",
      "        0.7408, 0.7103, 0.7537, 0.7534, 0.6761, 0.7071, 0.7048, 0.7694, 0.6509,\n",
      "        0.7300, 0.7618, 0.7072])\n",
      "tensor([0.7701, 0.7100, 0.7362, 0.7000, 0.7156, 0.6721, 0.7000, 0.6817, 0.7094,\n",
      "        0.5459, 0.7185, 0.7538, 0.7154, 0.7316, 0.7447, 0.7134, 0.7738, 0.6896,\n",
      "        0.7281, 0.7026, 0.6884, 0.7359, 0.6960, 0.7043, 0.7739, 0.7861, 0.7113,\n",
      "        0.7129, 0.6599, 0.7131])\n",
      "tensor([0.7696, 0.7396, 0.7006, 0.7198, 0.7203, 0.7460, 0.7091, 0.7381, 0.7995,\n",
      "        0.7295, 0.7142, 0.7535, 0.7681, 0.6973, 0.7182, 0.7668, 0.7268, 0.6931,\n",
      "        0.7783, 0.7328, 0.6120, 0.7094, 0.7035, 0.5064, 0.7215, 0.7563, 0.7606,\n",
      "        0.7039, 0.7256, 0.7467])\n",
      "tensor([0.7091, 0.7561, 0.7001, 0.7263, 0.7417, 0.7882, 0.6930, 0.7094, 0.7038,\n",
      "        0.7331, 0.7095, 0.7628, 0.7782, 0.7716, 0.7043, 0.6969, 0.7028, 0.7031,\n",
      "        0.7364, 0.7396, 0.7419, 0.7739, 0.3555, 0.7204, 0.6756, 0.7259, 0.7111,\n",
      "        0.7459, 0.7206, 0.7242])\n",
      "tensor([0.7708, 0.7834, 0.7320, 0.7417, 0.6978, 0.7290, 0.6936, 0.6785, 0.6940,\n",
      "        0.6926, 0.7338, 0.7574, 0.7153, 0.6977, 0.7662, 0.7074, 0.7624, 0.6748,\n",
      "        0.6790, 0.7536, 0.7291, 0.7003, 0.7392, 0.6883, 0.3860, 0.7253, 0.7708,\n",
      "        0.6811, 0.6806, 0.6923])\n",
      "tensor([0.7216, 0.7134, 0.7177, 0.7199, 0.7219, 0.7004, 0.7089, 0.6767, 0.6944,\n",
      "        0.7351, 0.6699, 0.7356, 0.7040, 0.7039, 0.7115, 0.6854, 0.7143, 0.7682,\n",
      "        0.7939, 0.7289, 0.7627, 0.7335, 0.7393, 0.7702, 0.7197, 0.6937, 0.6928,\n",
      "        0.7683, 0.7697, 0.7877])\n",
      "tensor([0.3581, 0.7659, 0.6945, 0.7021, 0.6373, 0.7800, 0.6502, 0.7210, 0.7506,\n",
      "        0.7371, 0.6913, 0.7506, 0.6547, 0.7398, 0.6169, 0.7228, 0.7760, 0.7102,\n",
      "        0.6986, 0.7142, 0.7675, 0.7522, 0.7175, 0.3374, 0.7367, 0.7219, 0.7110,\n",
      "        0.6914, 0.7315, 0.7008])\n",
      "tensor([0.7394, 0.7082, 0.7181, 0.7812, 0.7048, 0.7305, 0.7748, 0.7703, 0.7682,\n",
      "        0.7404, 0.7123, 0.7291, 0.7049, 0.7752, 0.7138, 0.7676, 0.7301, 0.7185,\n",
      "        0.7159, 0.7382, 0.7066, 0.7058, 0.7164, 0.7049, 0.7313, 0.6848, 0.6596,\n",
      "        0.7606, 0.7136, 0.6921])\n",
      "tensor([0.7534, 0.7456, 0.7102, 0.6932, 0.7279, 0.7079, 0.7322, 0.7098, 0.6835,\n",
      "        0.7445, 0.6663, 0.6883, 0.6739, 0.7197, 0.7722, 0.7697, 0.6737, 0.7846,\n",
      "        0.7137, 0.7116, 0.7585, 0.6948, 0.5924, 0.7639, 0.7207, 0.7370, 0.7146,\n",
      "        0.7532, 0.7291, 0.7110])\n",
      "tensor([0.6972, 0.6982, 0.7420, 0.7859, 0.7431, 0.6816, 0.6972, 0.7271, 0.7395,\n",
      "        0.7431, 0.7158, 0.7376, 0.7016, 0.7763, 0.6866, 0.7837, 0.7122, 0.6875,\n",
      "        0.3138, 0.6945, 0.7217, 0.6899, 0.7470, 0.7117, 0.7039, 0.7006, 0.7170,\n",
      "        0.7044, 0.7018, 0.7088])\n",
      "tensor([0.7121, 0.7695, 0.7153, 0.7081, 0.6620, 0.6952, 0.7171, 0.6881, 0.7466,\n",
      "        0.7354, 0.6599, 0.7740, 0.6978, 0.7384, 0.6794, 0.6737, 0.6873, 0.7838,\n",
      "        0.7260, 0.3743, 0.7069, 0.7245, 0.7311, 0.7019, 0.7278, 0.6961, 0.7656,\n",
      "        0.7945, 0.6811, 0.6967])\n",
      "tensor([0.7111, 0.7627, 0.7356, 0.7737, 0.7187, 0.7131, 0.6504, 0.7673, 0.7236,\n",
      "        0.6965, 0.6933, 0.7043, 0.7068, 0.7478, 0.7859, 0.3450, 0.5581, 0.6631,\n",
      "        0.6790, 0.7829, 0.7563, 0.7167, 0.7370, 0.6865, 0.7020, 0.7714, 0.7513,\n",
      "        0.7161, 0.7032, 0.7229])\n",
      "tensor([0.7811, 0.7065, 0.7122, 0.7329, 0.7105, 0.6791, 0.7252, 0.6872, 0.7119,\n",
      "        0.7526, 0.7731, 0.7692, 0.6673, 0.6473, 0.7196, 0.6899, 0.7234, 0.7167,\n",
      "        0.6048, 0.7667, 0.6919, 0.7484, 0.7029, 0.7209, 0.7151, 0.6944, 0.6986,\n",
      "        0.6718, 0.3450, 0.7070])\n",
      "tensor([0.7705, 0.6811, 0.7123, 0.7735, 0.7172, 0.5823, 0.7130, 0.7238, 0.7515,\n",
      "        0.7416, 0.6716, 0.7310, 0.7552, 0.3508, 0.7085, 0.7169, 0.7294, 0.7289,\n",
      "        0.7266, 0.7418, 0.6853, 0.6176, 0.7112, 0.7158, 0.6960, 0.7260, 0.6993,\n",
      "        0.7375, 0.7110, 0.7365])\n",
      "tensor([0.7028, 0.7214, 0.6592, 0.7413, 0.6993, 0.7612, 0.7260, 0.7430, 0.6982,\n",
      "        0.7568, 0.6881, 0.7242, 0.7250, 0.6200, 0.7559, 0.6928, 0.6203, 0.6293,\n",
      "        0.7690, 0.3276, 0.7118, 0.6126, 0.7101, 0.7052, 0.7592, 0.7261, 0.7405,\n",
      "        0.7346, 0.4199, 0.7251])\n",
      "tensor([0.7108, 0.7434, 0.5790, 0.7423, 0.2754, 0.7103, 0.7406, 0.7331, 0.7618,\n",
      "        0.7660, 0.7135, 0.7263, 0.7098, 0.7468, 0.7159, 0.7011, 0.7125, 0.7008,\n",
      "        0.7245, 0.7009, 0.7053, 0.7375, 0.6932, 0.6842, 0.7670, 0.7570, 0.7126,\n",
      "        0.6976, 0.7351, 0.7325])\n",
      "tensor([0.7531, 0.7491, 0.6630, 0.7127, 0.7279, 0.7067, 0.7709, 0.7494, 0.7825,\n",
      "        0.7496, 0.7355, 0.7805, 0.7066, 0.7199, 0.7268, 0.5966, 0.7338, 0.7143,\n",
      "        0.7240, 0.7555, 0.7230, 0.7589, 0.7185, 0.7697, 0.7890, 0.7595, 0.4009,\n",
      "        0.7238, 0.7472, 0.7386])\n",
      "tensor([0.7176, 0.7214, 0.7228, 0.7068, 0.6966, 0.7093, 0.7342, 0.7674, 0.6832,\n",
      "        0.7362, 0.7195, 0.7099, 0.7388, 0.7307, 0.7795, 0.7175, 0.7101, 0.7263,\n",
      "        0.7459, 0.7232, 0.3204, 0.2828, 0.7397, 0.7168, 0.7869, 0.7375, 0.7112,\n",
      "        0.7018, 0.6949, 0.6969])\n",
      "tensor([0.7749, 0.7266, 0.7203, 0.7056, 0.7005, 0.7378, 0.7158, 0.7247, 0.7338,\n",
      "        0.7059, 0.7249, 0.7018, 0.7071, 0.6756, 0.7397, 0.7747, 0.7221, 0.6921,\n",
      "        0.7133, 0.7147, 0.7356, 0.6964, 0.7344, 0.7809, 0.7132, 0.7135, 0.5983,\n",
      "        0.7323, 0.7282, 0.7101])\n",
      "T = 10000 || Samples/seconds : 0\n"
     ]
    }
   ],
   "source": [
    "all_samples_hist = []\n",
    "all_samples = []\n",
    "Ts = [0.05, 0.1, 0.5, 1, 10000][::-1]\n",
    "for T in Ts:\n",
    "    start = time.time()\n",
    "    samples = rejection_sampling(model1, matcher, 2000, T, visible_layers, hidden_layers)\n",
    "    all_samples_hist.append([x[1] for x in samples])\n",
    "    all_samples.append([x[0] for x in samples])\n",
    "    print(f\"T = {T} || Samples/seconds : {int(2000/(time.time()-start))}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = [torch.cat([s_.view(1, *s_.size()) for s_ in s],0) for s in all_samples]\n",
    "for T, s in zip(Ts, all_samples):\n",
    "    torch.save(s, f\"{DATA}/{DATASET}/gen_data/rbm_rejection_sampling_T_{T}.pt\")\n",
    "#     torch.save(s, f\"{DATA}/{DATASET}/gen_data/ind_rejection_sampling_T_{T}.pt\")\n",
    "#     torch.save(s, f\"{DATA}/{DATASET}/gen_data/natural.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
