{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "from config import *\n",
    "\n",
    "DATASET = \"PF00397\"\n",
    "sys.path.append(f\"{ROOT}\")\n",
    "device = \"cpu\"\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from ss_inference.data import SecondaryStructureRawDataset\n",
    "from ss_inference.model import NetSurfP2\n",
    "from ss_inference.utils import *\n",
    "\n",
    "from config import DATA\n",
    "from pgm.data import SequenceData\n",
    "from pgm.layers import GaussianLayer, OneHotLayer\n",
    "from pgm.edge import Edge\n",
    "from pgm.model import MRF\n",
    "from pgm.utils import *\n",
    "\n",
    "from pattern_matching.loss import *\n",
    "from pattern_matching.pattern import PatternMatching, Matching\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCA Rejection Sampling\n",
    "\n",
    "https://en.wikipedia.org/wiki/Rejection_sampling\n",
    "\n",
    "### Independant model\n",
    "\n",
    "Let's consider an independant model such that $E(x) = \\sum_i g_i(x_i) = g(x)$. We want to extend it to include secondary structure QA. We consider $r$ a pattern a $R$ the set of secondary structure matching pattern $r$.\n",
    "$$M(x) = \\sum_{s \\in R} \\mathbb P(s|x)$$\n",
    "\n",
    "Then $m(x) = - \\log(M(x))$. We can then establish that $E(x) = g(x) + m(x)$. If we want to weight the two value we set $E$ to be $E(x) = g(x) + \\frac{1}{T} m(x)$. We then have :\n",
    "\n",
    "$$\\mathbb{P}(x) = \\frac{1}{Z} G(x)M(x)^{1/T}$$\n",
    "\n",
    "How do we sample according to this probability ? Sampling with G(x) is easy but $M(x)$ is not invertible. We rely on rejection sampling.\n",
    "\n",
    "To do this we sample following to the process :\n",
    "- We sample $X$ according to $G(x)$ and $U$ according to a unifrom distrbituion in $[0,1]$\n",
    "- if $M(X)^{1/T} < U$ we accept the sample, else we reject the sample and go back to step 1\n",
    "\n",
    "We then have :\n",
    "$$\\mathbb{P}(X = x) \\propto G(x)M(x)^{1/T}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SS3 prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model netsurfp2-50"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ss3 = NetSurfP2(50, \"netsurfp2\")\n",
    "optimizer = optim.Adam(model_ss3.parameters(), lr=0.001)\n",
    "model_ss3.load_state_dict(torch.load(f\"{DATA}/secondary_structure/lstm_50feats.h5\"))\n",
    "model_ss3.eval()\n",
    "model_ss3 = model_ss3.to(\"cuda\")\n",
    "\n",
    "model_ss3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SequenceData(f\"{DATA}/{DATASET}\", dataset=\"full\")\n",
    "loader = DataLoader(dataset, batch_size = 100, \n",
    "                          shuffle = True)\n",
    "N, qv = dataset.raw_sequences.shape[1], dataset.raw_sequences.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.one_hot_categorical import OneHotCategorical\n",
    "\n",
    "independant = np.zeros((dataset.raw_sequences.shape[1], dataset.raw_sequences.shape[2]))\n",
    "for w, v in zip(dataset.weights,dataset.raw_sequences):\n",
    "    independant += w*v\n",
    "independant /= np.sum(dataset.weights)\n",
    "independant = torch.FloatTensor(independant).to(device)\n",
    "\n",
    "independant_sampler = OneHotCategorical(independant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pots = np.zeros((dataset.raw_sequences.shape[1], dataset.raw_sequences.shape[2]))\n",
    "for w, v in zip(dataset.weights,dataset.raw_sequences):\n",
    "    pots += w*v\n",
    "pots /= np.sum(dataset.weights)\n",
    "pots = pots.T\n",
    "pots = torch.FloatTensor((pots.T-np.mean(pots, 1)).T).reshape(-1).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAADnCAYAAAC9roUQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbrklEQVR4nO3deVjU9aIG8HeGTXADckMp0IijMjMgTrgvuKd2tVyOdjp5LoMYRmbmkh7r1ONzvR07WUSaXi29mqmZZhqaCKKCiOwwg2lqgaKoICAoA7P97h92uJmKrPOb5f38BzP85uWf93mfL8z8JIIggIiIzEMqdgAiInvC0iUiMiOWLhGRGbF0iYjMiKVLRGRGjvU92KlTJ8HX19dMUYiImufnG1WoNZjEjgHD7ZswVt+WPOyxekvX19cXGRkZrZOKiKgF5V6pwKxNqdDqjWJHQfHWhY98jMcLRGQTNif/glqD+IX7OCxdIrJ6FdU6xJ29AZMVvNeLpUtEVu/oTzfgIH3oEarFYekSkdXLKCxHtc7yjxYAli4R2YDMgvL7vvZ2d8WRN4Y/8Lw3x/hjyNNPPPD9gT098cUc5UOvnbw0FB5uTi0TFI/57wUiIktnMJpQWHa3Qc/9OP7nVk7zeCxdIrJqReVaODlIoTfef7zgIJXgv1+Qo7+PB65X1mDutgz811QZEs7dxGHNdYzw74x3J/VFWbUOmmu3637O3c0Jn87qhyfaOiP3SsV915wa1AN/G+wLZwcJcq5UYOX3GpgEIP+98diSUoDRvbugRm/EwK2PzsvjBSKyatV6I6SSB/+I5vuEG7anFmLcJydRqdXjOZlX3WMujlL89wtyqLalY8bG0+jczqXusTdGP4OMgjJMiknG0Z9uwtvDDQDwdOd2mKzwwvQNKZgYkwyjcK+EAaCtiyOyL5fjuU+TcObXsnrzcukSkVXTG0x4SOfiSrkWZ4srAQCaq7fh7eFa99jTndvhSnk1Cm5VAwD251zF7JCnAAADfD0x76tMAEDi+ZuoqNYBAIb4PQF5j4448NoQAICLkwNu3akFANQajEg4d7PuterD0iUiq+bkKMXD7sWg+93bgY0C0OaP/1JWz//0PuwhCSTYm1WENUfOP/CYwfj/P2F8zI0heLxARFbNzckBpkbeAedSyR14e7rhKc97Rwf/Edi97rEzBWV1xwYj/TvD3c0ZAHDqUimek3nhibb3vu7o6oQe7q5oLC5dIrJq3h6u0Bsb9yE3tQYTVnynxpY5z6KsWoeMgjL4d2sPAIhOuIBPZ/XDDwFDcebXWygqv3cEcfHmHXwUdx7bw0IgkUhgMAl493sNrlZoG/XakvrukaZUKgV+4A0RWboxa0/gYskdsWPUKd66ELXFFx76FjkeLxCR1evv6yF2hAZj6RKR1VP6eMDN2UHsGA3C0iUiqze2T1cYreEjxsDSJSIb4O7mjHF9u8IaPmiMpUtENmHusF5wcbT8IwaWLhHZBIW3+33vOrNULF0isgl6vR4BlRkQDLViR6kXS5eIrF5mZiaUSiXOp8bjJWUPuDpZbrVZbjIiosfQarVYtmwZJk6ciMWLF+PQoUN4b5oSnX73qWGWhqVLRFbp5MmTCAwMREFBAfLy8vDXv/4VEokELo4O2PSK0mL/b5elS0RWpbKyEvPnz8dLL72ENWvWYPfu3ejatet9z+ndrQO2/WcIXJ1EKl5BeOSHQbB0ichqHDp0CDKZDDqdDhqNBlOnTn3kc5W+ntgeFmL2xdvW2QH68muPvC8QS5eILF5paSlefvllREVFYcuWLdi8eTPc3d0f+3NKX0/sixyMJz1c0aaV/7jWxkmKJz1csTdyMASd9pE3bWPpEpHFEgQBu3fvhlwuR+fOnaFWqzF69OhGXaN3tw6IXzQCrwz0bbXibeMkxd8G+SJ+0Qj07tah3ufy83SJyCJdu3YNkZGRuHjxIr777jsMHDiwyddycXTAiol98Hxgdyz6JgdF5VrUGoxozsc1SCX3ruvt4Yq1M4Mg79GxYT/X9JckImp5giBg8+bNCAwMRGBgILKysppVuL8n79ERR98cgd0RAzFJ4QUXR2mjz3zdnB3g4ijFJIUXdkcMxNE3RzS4cAEuXSKyIJcuXUJERAQqKyuRkJAAhULRKq+j8HZHzKxgVFTrEP/TTWQUliGzsBwFt+7CyUEKqUQCCe7dK80kCNAbTfB9oi36+3hA6eOJsX27oqOrU5Nem6VLRKIzGo2Ijo7G6tWr8fbbb2PhwoVwdGz9enJ3c8b0/t6Y3t8bAGAwmlBUroVWb4TOYIKzoxSuTveOEBwdWuZggKVLRKLSaDRQqVRwdXVFamoq/Pz8RMvi6CCFb6e2rfoaPNMlIlHodDq8//77CA0NRVhYGI4dOyZq4ZoLly4RmV16ejrCwsLg4+OD7OxseHt7ix3JbLh0ichsqqursXjxYkyePBnLly/HwYMH7apwAZYuEZlJYmIiFAoFrl27Bo1Gg5deegkSiRXcX6eF8XiBiFrV7du3sXTpUhw6dAjr16/H888/L3YkUXHpElGrOXjwIGQyGYB7/6Vg74ULcOkSUSsoKSnBG2+8gbS0NGzbtg2hoaFiR7IYXLpE1GIEQcDXX38NuVyO7t27Iy8vj4X7B1y6RNQiioqKEBkZiYKCAhw4cAAhISFiR7JIXLpE1CwmkwkbN25Ev379oFQqkZmZycKtB5cuETXZhQsXMHfuXGi1WiQmJtb90YwejUuXiBrNYDDgX//6FwYNGoQpU6YgJSWFhdtAXLpE1Ch5eXlQqVRo3749zpw5g6efflrsSFaFS5eIGqS2thb/+Mc/MHr0aMybNw8JCQks3Cbg0iWix0pNTYVKpYKfnx9ycnLQo0cPsSNZLZYuET3S3bt3sXLlSuzcuRPR0dGYOXOmXX5eQkvi8QIRPVRCQgLkcjlKS0uh0Wjw5z//mYXbArh0ieg+FRUVWLx4MeLi4vD5559j0qRJYkeyKVy6RFTn+++/h0wmg7OzMzQaDQu3FXDpEhFu3LiBBQsWICsrCzt27MCIESPEjmSzuHSJ7JggCNi+fTsUCgV8fX2Rl5fHwm1lXLpEdury5ct49dVXcfXqVcTGxkKpVIodyS5w6RLZGZPJhPXr1yM4OBiDBw9GRkYGC9eMuHSJ7MjPP/+M8PBw6PV6nDx5En379hU7kt3h0iWyAwaDAf/85z8xePBgTJs2DcnJySxckXDpEtm43NxchIWFwdPTE+np6ejZs6fYkewaly6RjaqpqcHKlSsxduxYREVFIS4ujoVrAbh0iWxQSkoKVCoV+vTpg9zcXHh5eYkdiX7D0iWyIXfu3MGKFSuwZ88exMTEYNq0afy8BAvD4wUiGxEXFwe5XI7bt29Do9Fg+vTpLFwLxKVLZOXKy8uxaNEiHDt2DBs3bsSECRPEjkT14NIlsmL79u1DQEAA2rZtC41Gw8K1Aly6RFbo+vXriIqKglqtxu7duzFs2DCxI1EDcekSWRFBELB161YoFAr4+/sjNzeXhWtluHSJrERBQQHmzZuHmzdv4scff0RwcLDYkagJuHSJLJzJZEJMTAyUSiVGjhyJtLQ0Fq4V49IlsmDnzp1DeHg4BEFAcnIyevfuLXYkaiYuXSILpNfrsXr1agwdOhSzZs1CUlISC9dGcOkSWZisrCyoVCp07doVmZmZ8PHxETsStSAuXSILodVqsXz5ckyYMAELFy7E4cOHWbg2iEuXyAIkJydDpVJBoVAgLy8P3bp1EzsStRKWLpGIqqqqsHz5cuzbtw+fffYZXnzxRbEjUSvj8QKRSH788UfIZDJUV1cjPz+fhWsnuHSJzOzWrVtYtGgRTp48iU2bNmHcuHFiRyIz4tIlMhNBELBnzx7IZDK4u7tDrVazcO0Qly6RGRQXF2P+/Pk4d+4c9u7di8GDB4sdiUTCpUvUigRBwJdffonAwEAEBAQgOzubhWvnuHSJWsmvv/6KiIgIlJWVIS4uDkFBQWJHIgvApUvUwoxGI6Kjo/Hss89izJgxOHPmDAuX6nDpErWgs2fPQqVSwcnJCSkpKfD39xc7ElkYLl2iFqDT6bBq1SoMHz4cr7zyCo4fP87CpYfi0iVqpoyMDKhUKvTo0QNZWVl46qmnxI5EFoxLl6iJtFotli5dikmTJmHJkiWIjY1l4dJjsXSJmuDEiRNQKBQoLCyEWq3Gyy+/DIlEInYssgI8XiBqhMrKSixbtgwHDhzAunXrMHXqVLEjkZXh0iVqoNjYWMhkMhgMBuTn57NwqUm4dIkeo7S0FAsXLsTp06exZcsWjB49WuxIZMW4dIkeQRAE7Nq1CzKZDF26dEFeXh4Ll5qNS5foIa5evYr58+fj4sWL2L9/PwYOHCh2JLIRXLpEvyMIAjZt2oSgoCAEBQUhKyuLhUstikuX6DeXLl3C3LlzUVVVhYSEBCgUCrEjkQ3i0iW7ZzQasXbtWgwYMAATJ07E6dOnWbjUarh0ya5pNBqoVCq4uroiNTUVfn5+YkciG8elS3ZJp9Ph/fffR2hoKFQqFY4dO8bCJbPg0iW7k5aWBpVKBR8fH2RnZ8Pb21vsSGRHWLpkN6qrq/Huu+/iq6++wscff4xZs2bx8xLI7Hi8QHYhMTERCoUCxcXFUKvVmD17NguXRMGlSzbt9u3bWLJkCQ4fPoz169fj+eefFzsS2TkuXbJZBw8ehEwmg1QqhUajYeGSReDSJZtTUlKCBQsWID09Hdu2bUNoaKjYkYjqcOmSzRAEAV9//TXkcjm8vb2Rl5fHwiWLw6VLNuHKlSuIjIxEYWEhDhw4gJCQELEjET0Uly5ZNZPJhA0bNiA4OBghISHIzMxk4ZJF49Ilq3XhwgXMnTsXNTU1OH78OAICAsSORPRYXLpkdQwGAz788EMMGjQIU6ZMwalTp1i4ZDW4dMmq5OXlQaVSoUOHDkhLS0OvXr3EjkTUKFy6ZBVqa2vx7rvvYvTo0Zg3bx7i4+NZuGSVuHTJ4qWmpkKlUsHPzw85OTno0aOH2JGImoylSxbr7t27WLlyJXbt2oXo6GjMmDGDn5dAVo/HC2SR4uPjIZfLUVpaCo1Gg5kzZ7JwySZw6ZJFqaiowFtvvYWjR49iw4YNmDhxotiRiFoUly5ZjP379yMgIAAuLi7QaDQsXLJJXLokuhs3buD1119HTk4Odu7cieHDh4sdiajVcOmSaARBwPbt26FQKNCzZ0/k5uaycMnmcemSKC5fvox58+bh2rVriI2NhVKpFDsSkVlw6ZJZmUwmrFu3DsHBwRg6dCgyMjJYuGRXuHTJbM6fP4/w8HAYjUYkJSWhT58+YkciMjsuXWp1BoMBH3zwAYYMGYIZM2awcMmucelSq8rJyYFKpYKnpyfS09PRs2dPsSMRiYpLl1pFTU0N/v73v2PcuHGIiopCXFwcC5cIXLrUCk6dOgWVSoW+ffsiNzcXXl5eYkcishgsXWoxd+7cwYoVK/Dtt98iJiYG06ZNEzsSkcXh8QK1iLi4OMhkMlRWVkKj0bBwiR6BS5eapaysDG+99RYSExOxceNGjB8/XuxIRBaNS5eabO/evZDJZGjXrh3UajULl6gBuHSp0a5fv46oqChoNBp88803GDp0qNiRiKwGly41mCAI2Lp1KxQKBfz9/ZGTk8PCJWokLl1qkIKCAkRERKCkpARHjhxBv379xI5EZJW4dKleJpMJMTExUCqVCA0NRVpaGguXqBm4dOmRfvrpJ4SHh0MikSA5ORm9e/cWOxKR1ePSpQfo9XqsXr0aw4YNw+zZs3Hy5EkWLlEL4dKl+2RlZSEsLAzdunVDZmYmfHx8xI5EZFO4dAkAoNVq8fbbb2PChAlYtGgRDh8+zMIlagVcuoSkpCSEh4dDoVBArVaja9euYkcislksXTtWVVWFt99+G/v370dMTAxefPFFsSMR2TweL9ipw4cPQyaTQavVQqPRsHCJzIRL187cunULb775JpKSkrB582aMHTtW7EhEdoVL104IgoBvvvkGMpkMnp6eUKvVLFwiEXDp2oFr167htddew/nz57Fv3z4MGjRI7EhEdotL14YJgoAvvvgCgYGBkMlkyM7OZuESiYxL10b98ssviIiIQEVFBeLj4xEYGCh2JCICl67NMRqN+OSTTxASEoJx48YhNTWVhUtkQbh0bcjZs2ehUqng7OyMlJQU+Pv7ix2JiP6AS9cG6HQ6rFq1CiNGjMCcOXOQmJjIwiWyUFy6Vi49PR0qlQre3t7IysrCk08+KXYkIqoHl66Vqq6uxtKlSzF58mQsW7YMsbGxLFwiK8DStUInTpxAYGAgLl++DLVajb/85S+QSCRixyKiBuDxghWprKzEsmXLcPDgQaxbtw5TpkwROxIRNRKXrpWIjY2FTCaD0WiERqNh4RJZKS5dC1dSUoKFCxciNTUVW7duxahRo8SORETNwKVroQRBwK5duyCXy9GtWzfk5eWxcIlsAJeuBbp69SoiIyNx6dIlfP/99xgwYIDYkYiohXDpWhBBELBp0yYEBQUhODgYWVlZLFwiG8OlayEuXbqEuXPnoqqqCseOHYNcLhc7EhG1Ai5dkRmNRnz00UcYMGAAJk2ahNOnT7NwiWwYl66INBoNwsLC0LZtW6SmpsLPz0/sSETUyrh0RaDT6fDee+8hNDQU4eHhSEhIYOES2QkuXTNLS0tDWFgYevbsiezsbHh7e4sdiYjMiKVrJtXV1XjnnXewY8cOfPzxx5g1axY/L4HIDvF4wQwSExMhl8tx/fp1qNVqzJ49m4VLZKe4dFtRRUUFli5disOHD+Pzzz/H5MmTxY5ERCLj0m0lBw4cgEwmg1QqhUajYeESEQAu3RZ38+ZNLFiwABkZGfjqq68wcuRIsSMRkQXh0m0hgiBgx44dkMvlePLJJ5GXl8fCJaIHcOm2gCtXriAyMhKXL1/GDz/8gGeffVbsSERkobh0m8FkMmHDhg0IDg5GSEgIMjIyWLhEVC8u3Sa6cOECwsPDUVtbi+PHjyMgIEDsSERkBbh0G8lgMGDNmjUYNGgQXnjhBZw6dYqFS0QNxqXbCLm5uVCpVHB3d0daWhp69eoldiQisjJcug1QW1uLd955B2PGjEFkZCSOHj3KwiWiJuHSfYzTp09DpVLB398fubm56N69u9iRiMiKsXQf4c6dO1i5ciV2796N6OhozJgxg5+XQETNxuOFhzh69CjkcjnKysqg0Wgwc+ZMFi4RtQgu3d8pLy/H4sWLER8fjw0bNuC5554TOxIR2Rgu3d989913kMlkaNOmDdRqNQuXiFqF3S/dGzdu4PXXX0dOTg527tyJ4cOHix2JiGyY3S5dQRCwbds2KBQK9OrVC7m5uSxcImp1drl0CwsL8eqrr6K4uBiHDh1C//79xY5ERHbCrpauyWTCunXr0L9/fwwbNgzp6eksXCIyK7tZuufPn0d4eDiMRiOSkpLQp08fsSMRkR2y+aWr1+vxwQcfYMiQIZg5cyYLl4hEZdNLNzs7GyqVCp06dUJGRgZ8fX3FjkREdq5FS9dgNKGoXItqvRF6gwlOjlK4OTnA28MVjg7mG9U1NTVYtWoVNm3ahDVr1mDOnDl8RxkRWYRmlW5FtQ5Hf7qBjMJyZBaUo7DsLpwcpJBKJJBIAEEATIIAvdEEH8+26O/rAaWPB8b26Qp3N+eW+h3uc+rUKahUKgQEBCA3NxdeXl6t8jpERE0hEQThkQ8qlUohIyPjge/nFVVgU9IviDt7Aw5SCap1xga/oJuzA4wmAeP6dsXcYb2g8HZvUvA/qqqqwooVK7B3717ExMRg2rRpLXJdIqLGkkgkmYIgKB/2WKOWbl5RBd7ak4uici1qDUaYHt3Xj/Tvgo5VFyP+p5vw9nDF2plBkPfo2PiL/ebIkSOYN28eRo4cCY1GA09PzyZfi4ioNTWodGsNRnwU9zO2pRagRm9qkRc2CYBWb8SFm3cwY2MK5gzyxaKx/nBxdGjwNcrKyrBo0SIcP34cGzduxPjx41skGxFRa3nsX7fOXa/EmLUnsL0FC/ePavQmbDtdgDFrT+Dc9coG/czevXshk8nQvn17qNVqFi4RWYV6z3T7KIIEyQsfNOrMtrnaOjvgf/8zBErfhx8RFBcXIyoqCvn5+di8eTOGDh1qtmxERA1R35luvUu3oLTarIULAHd1Rvz1yzRkFJTd931BELBlyxYEBgaid+/eyMnJYeESkdWp90zXVM8Kbk1avRGvbEnDvsjB6N2tAwoKChAREYHS0lLExcUhKChIlFxERM1lsW8DrtYZEb4tA2ujP4VSqcSoUaNw5swZFi4RWTWLfhtwUeltbLl2E6dOncKf/vQnseMQETWbxS5dAICDM/Q9h0DXrpvYSYiIWoRlly6AGoMJi77JETsGEVGLsPjSBYCici3yiirEjkFE1GxWUbq1BiM2Jf8idgwiomazitI1CUBc/g3c1urFjkJE1CxWUboA4CCV4OjZG2LHICJqFqsp3WqdERmFZY9/IhGRBbOa0gWAzMJysSMQETWLVZVuwa27MBhb55POiIjMod53pP2w80usSKlFSVUtZN074MPpgdDqjUgvKMNI/y4YH30S04O9IffuiH8cyAcAfDFHiU0nf0Hqr2UY9kwnvDnGH84OUhSWVWPJt7mo1hmRvDQUe7OKMLp3Vzg6SPDa11m4VHIXbs4OeP/5AMi9O0IQgOiEC/gx/3rdddo4SlFrMJn1fmtERC2p3vbauvNbLBl37+23H04PxHsH8/Hi5ykNurCHmxOiQv3wl81nMPmzZKiLKhA+tGfd42V39Zj8WTK+OnMZc4f1AgAsGPUMqmoNmBCdhOc+TULKpdL7rjPzf1Jxt9bQ1N+ViEh09S7d5Qvno8yxDdq7OKKDqxPO/HrvD1nfZV/FSP8u9V6431MeeKZLe+x9dRAAwMlBiqzL//8Ghx/ziwEAmqu3MSHg3tt8h/h1wus7s+qeU1ljwKjeXequI5VK0MHVqQm/JhGRZai3dPuPmgyvv32CDm0c8agPOzeYBEh/d3vzf99uRwIg+WIJFux6+Ft4dYZ7Z7NGkwBHqaTuZ/74Kr+/TjsXR+yZNwh9vDo8/jcjIrJA9R4vODo64pku7VBZY0BVjQFKHw8AwNSgHnXPKSqvRl+vDpBIAK+ObRDofe8Gk9lXKtDfxxM+T7gBANo4SdGzU9t6wyRdKMGcQb51X3do43jfdUyCADenht9DjYjI0tS7dNPjD2BbvhYXbt7Bkm9z6/6QdvLnkrrnZBSW40p5NY68MRw/36hC/rV79zgru6vD4j25+HRWPzj/9oevj46ex6+ldx/5ejGJF7FqigxH3hgOkyDgk4QLOJJ/ve46Lo5SPPVbiRMRWaN675Hm4vWM4PW3Tx74vre7K76Y8yzGR59szWwPeKZLOxx9c4RZX5OIqLGafI80S9P/t+MNIiJr1aTSLarQmn3lujk7QOnz8DsEExFZC6tZukaTgLF9u4odg4ioWayidKUSYFxAV3Tk/+gSkZWzitJ1cXRAxLCnxY5BRNRs9f73goNbR8GxY/3vPDMHwaCv0ZcW5oudg4iogXwEQej8sAfqLV0iImpZVnG8QERkK1i6RERmxNIlIjIjli4RkRmxdImIzOj/AA4aHDxxd8kBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 : 0.004792404361069202\n",
      "Iteration 200 : 3.2124345841875765\n",
      "Iteration 400 : 12.83503515078337\n",
      "Iteration 600 : 29.430040588515112\n",
      "Iteration 800 : 54.27352224840433\n",
      "Iteration 1000 : 89.42802830590517\n",
      "Iteration 1200 : 140.5916180665663\n",
      "Iteration 1400 : 216.40690044118674\n",
      "Iteration 1600 : 313.16912106229574\n",
      "Iteration 1800 : 427.01079908563406\n",
      "Estimated Z : 15.385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.385404586791992"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visible_layers = [\"sequence\"]\n",
    "hidden_layers = [\"hidden\"]\n",
    "\n",
    "v = OneHotLayer(pots, N=N, q=qv, name=\"sequence\")\n",
    "h = GaussianLayer(N=200, name=\"hidden\")\n",
    "\n",
    "E = [(v.name, h.name)]\n",
    "\n",
    "model1 = MRF(layers = {v.name: v,\n",
    "                    h.name: h},\n",
    "            edges = E,\n",
    "            name = \"\")\n",
    "\n",
    "for visible in visible_layers:\n",
    "    edge = model1.get_edge(visible, \"hidden\")\n",
    "    \n",
    "model1.load(f\"{DATA}/{DATASET}/weights/seq-reg-200_630.h5\")\n",
    "model1.ais(n_inter = 2000, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rejection Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def fillna(x, value = 0):\n",
    "    idx = torch.where(x!=x)\n",
    "    x[idx] = 0\n",
    "    return x\n",
    "\n",
    "def local_rejection_sampling(model, matcher, n_samples, T, visible_layers = None, hidden_layers = None):\n",
    "    samples = []\n",
    "    while(True):\n",
    "        for batch_idx, data in enumerate(loader):\n",
    "            print(f\"{len(samples)}/{n_samples} [{int(100*len(samples)/n_samples)}%]\", end=\"\\r\")\n",
    "            if model == \"natural\":\n",
    "                x = data[0].permute(0,2,1)\n",
    "            elif model == \"independant\":\n",
    "                x = independant_sampler.sample_n(200).permute(0,2,1)\n",
    "            else:\n",
    "                d_0 = {k: v.float().permute(0, 2, 1).to(device) for k, v in zip(LAYERS_NAME, data[:1]) if k in visible_layers}\n",
    "                batch_size, q, N = d_0[\"sequence\"].size()\n",
    "                _, d_f = model.gibbs_sampling(d_0, visible_layers, hidden_layers, k=30)\n",
    "                x = d_f[\"sequence\"]\n",
    "                \n",
    "            m = matcher(Matching(x),30).detach().clamp(0,1)\n",
    "            u = torch.arange(30).reshape(1,1,-1)\n",
    "            #X = scaler.transform((m*u).sum(-1))\n",
    "            #X_max = torch.tensor(np.max(np.abs(X), 1)/STD)\n",
    "            \n",
    "            X = (m*u).sum(-1)\n",
    "            gm_scores = torch.zeros(*X.size())\n",
    "            for k,gm in enumerate(gms):\n",
    "                X_ = X[:,k:k+1]\n",
    "                X_[:,0] = fillna(X_[:,0],0)\n",
    "                gm_scores[:,k] = torch.tensor(gm.score_samples(X_))\n",
    "            mx = gm_scores.min(-1).values.clamp(-15,0)\n",
    "            #mx = torch.log(1-torch.pow(torch.erf(X_max/np.sqrt(2)),len_pat))\n",
    "            for x_, mx_ in zip(x, mx):\n",
    "                if len(samples) >= n_samples:\n",
    "                    return samples\n",
    "                thr = np.exp(mx_/T)\n",
    "                if random() < thr:\n",
    "                    samples.append((x_, -mx_))\n",
    "    return samples\n",
    "\n",
    "def rejection_sampling(model, matcher, n_samples, T, visible_layers = None, hidden_layers = None):\n",
    "    samples = []\n",
    "    while(True):\n",
    "        for batch_idx, data in enumerate(loader):\n",
    "            print(f\"{len(samples)}/{n_samples} [{int(100*len(samples)/n_samples)}%]\", end=\"\\r\")\n",
    "            if model == \"natural\":\n",
    "                x = data[0].permute(0,2,1)\n",
    "            elif model == \"independant\":\n",
    "                x = independant_sampler.sample_n(200).permute(0,2,1)\n",
    "            else:\n",
    "                d_0 = {k: v.float().permute(0, 2, 1).to(device) for k, v in zip(LAYERS_NAME, data[:1]) if k in visible_layers}\n",
    "                batch_size, q, N = d_0[\"sequence\"].size()\n",
    "                _, d_f = model.gibbs_sampling(d_0, visible_layers, hidden_layers, k=30)\n",
    "                x = d_f[\"sequence\"]\n",
    "            m = matcher(Matching(x))\n",
    "            mx = (m.M/m.ls).detach()\n",
    "            for x_, mx_ in zip(x, mx):\n",
    "                if len(samples) >= n_samples:\n",
    "                    return samples\n",
    "                thr = np.exp(mx_/T)\n",
    "                if random() < thr:\n",
    "                    samples.append((x_, -mx_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_hmm = torch.tensor(dataset[0][3]).t()[20:]\n",
    "torch.save(seq_hmm, f\"{DATA}/{DATASET}/hmm.pt\")\n",
    "_, size = seq_hmm.size()\n",
    "\n",
    "n_patterns, c_patterns, _ =  pickle.load(open(f\"{DATA}/{DATASET}/patterns.pkl\",\"rb\"))\n",
    "regexes = []\n",
    "for x in n_patterns:\n",
    "    if len(x):\n",
    "        regexes.append([(i,None,None) for i in x])\n",
    "size = 150\n",
    "Q = np.ones((3, size+1, size+1)) * (-np.inf)\n",
    "e = size\n",
    "for i in range(size+1):\n",
    "    Q[:3, i, i+1:] = 0\n",
    "Q = Q.reshape(1, *Q.shape)\n",
    "\n",
    "ss_hmm = pickle.load(open(f\"{DATA}/{DATASET}/ss_profile.pkl\", \"rb\"))\n",
    "seq_hmm = torch.load(f\"{DATA}/{DATASET}/hmm.pt\")\n",
    "\n",
    "#matcher = PatternMatchingLoss(model_ss3, pattern = regexes[1], Q = Q ,\n",
    "#                          seq_hmm = seq_hmm, ss_hmm = ss_hmm, \n",
    "#                          size = size, name = c_patterns[1])\n",
    "matcher = LocalPatternMatchingLoss(model_ss3, pattern = regexes[0], Q = Q, \n",
    "                                   seq_hmm = seq_hmm, ss_hmm = ss_hmm, \n",
    "                                   size = size, name = c_patterns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "575it [06:45,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "L_ = []\n",
    "for batch_idx, data in tqdm(enumerate(loader)):\n",
    "    x = data[0].permute(0,2,1)\n",
    "    L = matcher(Matching(x), 30)\n",
    "    L_.append(L.detach())\n",
    "L_ = torch.cat(L_,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "u = torch.arange(30).reshape(1,1,-1)\n",
    "X = (L_*u).sum(-1)\n",
    "\n",
    "gms = [KernelDensity(bandwidth=0.5, algorithm='auto', kernel='gaussian').fit(X[:,i:i+1]) for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (30) must match the size of tensor b (15) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7d26bf2d5a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (30) must match the size of tensor b (15) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from random import random\n",
    "\n",
    "u = torch.arange(15).reshape(1,1,15)\n",
    "X = (L_*u).sum(-1)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X)\n",
    "X_n = scaler.transform(X)\n",
    "\n",
    "STD = 1/(2**0.5*torch.erfinv(torch.tensor(0.5))).item()\n",
    "X_max = torch.tensor(np.max(np.abs(X_n), 1)/STD)\n",
    "\n",
    "len_pat = X_n.shape[-1]\n",
    "print(f\"std = {STD:.4f} || len pattern = {len_pat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850/2000 [42%]\r"
     ]
    }
   ],
   "source": [
    "all_samples_hist = []\n",
    "all_samples = []\n",
    "Ts = [0.2]\n",
    "for T in Ts:\n",
    "    start = time.time()\n",
    "    samples = local_rejection_sampling(model1, matcher, 2000, T, visible_layers, hidden_layers)\n",
    "    all_samples_hist.append([x[1] for x in samples])\n",
    "    all_samples.append([x[0] for x in samples])\n",
    "    print(f\"T = {T} || Samples/seconds : {int(2000/(time.time()-start))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = [torch.cat([s_.view(1, *s_.size()) for s_ in s],0) for s in all_samples]\n",
    "for T, s in zip(Ts, all_samples):\n",
    "    torch.save(s, f\"{DATA}/{DATASET}/gen_data/rbm_local_rejection_sampling_T_{T}.pt\")\n",
    "    #torch.save(s, f\"{DATA}/{DATASET}/gen_data/ind_local_rejection_sampling_T_{T}.pt\")\n",
    "    #torch.save(s, f\"{DATA}/{DATASET}/gen_data/natural.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
